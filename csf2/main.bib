% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries
@article{patrignani2020use,
  author    = {Marco Patrignani},
  title     = {Why Should Anyone use Colours? or, Syntax Highlighting Beyond Code
               Snippets},
  journal   = {CoRR},
  volume    = {abs/2001.11334},
  year      = {2020},
  url       = {https://arxiv.org/abs/2001.11334},
  archivePrefix = {arXiv},
  eprint    = {2001.11334},
}
@inproceedings{cauligi2019fact,
author = {Cauligi, Sunjay and Soeller, Gary and Johannesmeyer, Brian and Brown, Fraser and Wahby, Riad S. and Renner, John and Gr\'{e}goire, Benjamin and Barthe, Gilles and Jhala, Ranjit and Stefan, Deian},
title = {FaCT: A DSL for Timing-Sensitive Computation},
year = {2019},
isbn = {9781450367127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314221.3314605},
doi = {10.1145/3314221.3314605},
abstract = {Real-world cryptographic code is often written in a subset of C intended to execute in constant-time, thereby avoiding timing side channel vulnerabilities. This C subset eschews structured programming as we know it: if-statements, looping constructs, and procedural abstractions can leak timing information when handling sensitive data. The resulting obfuscation has led to subtle bugs, even in widely-used high-profile libraries like OpenSSL. To address the challenge of writing constant-time cryptographic code, we present FaCT, a crypto DSL that provides high-level but safe language constructs. The FaCT compiler uses a secrecy type system to automatically transform potentially timing-sensitive high-level code into low-level, constant-time LLVM bitcode. We develop the language and type system, formalize the constant-time transformation, and present an empirical evaluation that uses FaCT to implement core crypto routines from several open-source projects including OpenSSL, libsodium, and curve25519-donna. Our evaluation shows that FaCT’s design makes it possible to write readable, high-level cryptographic code, with efficient, constant-time behavior.},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {174–189},
numpages = {16},
keywords = {program transformation, cryptography, domain-specific language},
location = {Phoenix, AZ, USA},
series = {PLDI 2019}
}
@inproceedings{barthe2018sec,
  author={Barthe, Gilles and Grégoire, Benjamin and Laporte, Vincent},
  booktitle={2018 IEEE 31st Computer Security Foundations Symposium (CSF)}, 
  title={Secure Compilation of Side-Channel Countermeasures: The Case of Cryptographic “Constant-Time”}, 
  year={2018},
  volume={},
  number={},
  pages={328-343},
  doi={10.1109/CSF.2018.00031}
}
@inproceedings{abate2019jour,
  author={Abate, Carmine and Blanco, Roberto and Garg, Deepak and Hritcu, Catalin and Patrignani, Marco and Thibault, Jérémy},
  booktitle={2019 IEEE 32nd Computer Security Foundations Symposium (CSF)}, 
  title={Journey Beyond Full Abstraction: Exploring Robust Property Preservation for Secure Compilation}, 
  year={2019},
  volume={},
  number={},
  pages={256-25615},
  doi={10.1109/CSF.2019.00025}
}
@misc{patrignani2022universal,
      title={Universal Composability is Robust Compilation}, 
      author={Marco Patrignani and Robert Künnemann and Riad S. Wahby},
      year={2022},
      eprint={1910.08634},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}
@inproceedings{patrignani2023blame,
 author = {Patrignani, Marco and Kruse, Matthis},
 maintitle = {ACM SIGPLAN Workshop on Principles of Secure Compilation},
 month = {January},
 title = {Blame-Preserving Secure Compilation},
 year = {2023}
}
@inproceedings{kruse2022csc,
 author = {Kruse, Matthis and Patrignani, Marco},
 maintitle = {ACM SIGPLAN Workshop on Principles of Secure Compilation},
 month = {January},
 title = {Composing Secure Compilers},
 year = {2022}
}
@article{patrignani2019survey,
author = {Patrignani, Marco and Ahmed, Amal and Clarke, Dave},
title = {Formal Approaches to Secure Compilation: A Survey of Fully Abstract Compilation and Related Work},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3280984},
doi = {10.1145/3280984},
abstract = {Secure compilation is a discipline aimed at developing compilers that preserve the security properties of the source programs they take as input in the target programs they produce as output. This discipline is broad in scope, targeting languages with a variety of features (including objects, higher-order functions, dynamic memory allocation, call/cc, concurrency) and employing a range of different techniques to ensure that source-level security is preserved at the target level. This article provides a survey of the existing literature on formal approaches to secure compilation with a focus on those that prove fully abstract compilation, which has been the criterion adopted by much of the literature thus far. This article then describes the formal techniques employed to prove secure compilation in existing work, introducing relevant terminology, and discussing the merits and limitations of each work. Finally, this article discusses open challenges and possible directions for future work in secure compilation.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {125},
numpages = {36},
keywords = {Secure compilation, type preserving compilation, contextual equivalence, program equivalence, fully abstract compilation}
}
@article{abate2021extacc,
author = {Abate, Carmine and Blanco, Roberto and Ciob\^{a}c\u{a}, \c{S}tefan and Durier, Adrien and Garg, Deepak and Hri\c{t}cu, C\u{a}t\u{a}lin and Patrignani, Marco and Tanter, \'{E}ric and Thibault, J\'{e}r\'{e}my},
title = {An Extended Account of Trace-Relating Compiler Correctness and Secure Compilation},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0164-0925},
url = {https://doi.org/10.1145/3460860},
doi = {10.1145/3460860},
abstract = {Compiler correctness, in its simplest form, is defined as the inclusion of the set of traces of the compiled program in the set of traces of the original program. This is equivalent to the preservation of all trace properties. Here, traces collect, for instance, the externally observable events of each execution. However, this definition requires the set of traces of the source and target languages to be the same, which is not the case when the languages are far apart or when observations are fine-grained. To overcome this issue, we study a generalized compiler correctness definition, which uses source and target traces drawn from potentially different sets and connected by an arbitrary relation. We set out to understand what guarantees this generalized compiler correctness definition gives us when instantiated with a non-trivial relation on traces. When this trace relation is not equality, it is no longer possible to preserve the trace properties of the source program unchanged. Instead, we provide a generic characterization of the target trace property ensured by correctly compiling a program that satisfies a given source property, and dually, of the source trace property one is required to show to obtain a certain target property for the compiled code. We show that this view on compiler correctness can naturally account for undefined behavior, resource exhaustion, different source and target values, side channels, and various abstraction mismatches. Finally, we show that the same generalization also applies to many definitions of secure compilation, which characterize the protection of a compiled program linked against adversarial code.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {nov},
articleno = {14},
numpages = {48},
keywords = {Trace properties, Galois connection, formal languages, hyperproperties, property-preserving compilation, compiler correctness, secure compilation, programming languages}
}
@inproceedings{clarkson2008hyper,
  author={Clarkson, Michael R. and Schneider, Fred B.},
  booktitle={2008 21st IEEE Computer Security Foundations Symposium}, 
  title={Hyperproperties}, 
  year={2008},
  volume={},
  number={},
  pages={51-65},
  doi={10.1109/CSF.2008.7}
}
@article{patrignani2021rsc,
author = {Patrignani, Marco and Garg, Deepak},
title = {Robustly Safe Compilation, an Efficient Form of Secure Compilation},
year = {2021},
issue_date = {March 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0164-0925},
url = {https://doi.org/10.1145/3436809},
doi = {10.1145/3436809},
abstract = {Security-preserving compilers generate compiled code that withstands target-level attacks such as alteration of control flow, data leaks, or memory corruption. Many existing security-preserving compilers are proven to be fully abstract, meaning that they reflect and preserve observational equivalence. Fully abstract compilation is strong and useful but, in certain cases, comes at the cost of requiring expensive runtime constructs in compiled code. These constructs may have no relevance for security, but are needed to accommodate differences between the source and target languages that fully abstract compilation necessarily needs.As an alternative to fully abstract compilation, this article explores a different criterion for secure compilation called robustly safe compilation or RSC. Briefly, this criterion means that the compiled code preserves relevant safety properties of the source program against all adversarial contexts interacting with the compiled program. We show that RSC can be proved more easily than fully abstract compilation and also often results in more efficient code. We also present two different proof techniques for establishing that a compiler attains RSC and, to illustrate them, develop three illustrative robustly safe compilers that rely on different target-level protection mechanisms. We then proceed to turn one of our compilers into a fully abstract one and through this example argue that proving RSC can be simpler than proving full abstraction.To better explain and clarify notions, this article uses syntax highlighting in a way that colourblind and black-8-white readers can benefit from Reference [58]. For a better experience, please print or view this article in colour.1},
journal = {ACM Trans. Program. Lang. Syst.},
month = {feb},
articleno = {1},
numpages = {41},
keywords = {robust safety, fully abstract compilation, robustly-safe compilation, programming languages, formal languages, Secure compilation}
}

@article{nagarakatte2009soft,
author = {Nagarakatte, Santosh and Zhao, Jianzhou and Martin, Milo M.K. and Zdancewic, Steve},
title = {SoftBound: Highly Compatible and Complete Spatial Memory Safety for c},
year = {2009},
issue_date = {June 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/1543135.1542504},
doi = {10.1145/1543135.1542504},
journal = {SIGPLAN Not.},
month = {jun},
pages = {245–258},
numpages = {14},
keywords = {buffer overflows, c, spatial memory safety}
}
@article{nagarakatte2010cets,
author = {Nagarakatte, Santosh and Zhao, Jianzhou and Martin, Milo M.K. and Zdancewic, Steve},
title = {CETS: Compiler Enforced Temporal Safety for C},
year = {2010},
issue_date = {August 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/1837855.1806657},
doi = {10.1145/1837855.1806657},
journal = {SIGPLAN Not.},
month = {jun},
pages = {31–40},
numpages = {10},
keywords = {temporal errors, c, memory safety, dangling pointers}
}
@article{michael2023mswasm,
author = {Michael, Alexandra E. and Gollamudi, Anitha and Bosamiya, Jay and Johnson, Evan and Denlinger, Aidan and Disselkoen, Craig and Watt, Conrad and Parno, Bryan and Patrignani, Marco and Vassena, Marco and Stefan, Deian},
title = {MSWasm: Soundly Enforcing Memory-Safe Execution of Unsafe Code},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {POPL},
url = {https://doi.org/10.1145/3571208},
doi = {10.1145/3571208},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {15},
numpages = {30},
keywords = {Semantics, Memory-safety, WebAssembly, Secure Compilation}
}
@inproceedings{korashy2021capableptrs,
  author={El-Korashy, Akram and Tsampas, Stelios and Patrignani, Marco and Devriese, Dominique and Garg, Deepak and Piessens, Frank},
  booktitle={2021 IEEE 34th Computer Security Foundations Symposium (CSF)}, 
  title={CapablePtrs: Securely Compiling Partial Programs Using the Pointers-as-Capabilities Principle}, 
  year={2021},
  volume={},
  number={},
  pages={1-16},
  doi={10.1109/CSF51468.2021.00036}
}
@inproceedings{morrisett2005L3,
author="Morrisett, Greg
and Ahmed, Amal
and Fluet, Matthew",
editor="Urzyczyn, Pawe{\l}",
title="L3: A Linear Language with Locations",
booktitle="Typed Lambda Calculi and Applications",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="293--307",
abstract="We explore foundational typing support for strong updates --- updating a memory cell to hold values of unrelated types at different points in time. We present a simple, but expressive type system based upon standard linear logic, one that also enjoys a simple semantic interpretation for types that is closely related to models for spatial logics. The typing interpretation is strong enough that, in spite of the fact that our core calculus supports shared, mutable references and cyclic graphs, every well-typed program terminates.",
isbn="978-3-540-32014-2"
}
@inproceedings{akritidis2009baggy,
author = {Akritidis, Periklis and Costa, Manuel and Castro, Miguel and Hand, Steven},
title = {Baggy Bounds Checking: An Efficient and Backwards-Compatible Defense against out-of-Bounds Errors},
year = {2009},
publisher = {USENIX Association},
address = {USA},
abstract = {Attacks that exploit out-of-bounds errors in C and C++ programs are still prevalent despite many years of research on bounds checking. Previous backwards compatible bounds checking techniques, which can be applied to unmodified C and C++ programs, maintain a data structure with the bounds for each allocated object and perform lookups in this data structure to check if pointers remain within bounds. This data structure can grow large and the lookups are expensive.In this paper we present a backwards compatible bounds checking technique that substantially reduces performance overhead. The key insight is to constrain the sizes of allocated memory regions and their alignment to enable efficient bounds lookups and hence efficient bounds checks at runtime. Our technique has low overhead in practice--only 8% throughput decrease for Apache-- and is more than two times faster than the fastest previous technique and about five times faster--using less memory--than recording object bounds using a splay tree.},
booktitle = {Proceedings of the 18th Conference on USENIX Security Symposium},
pages = {51–66},
numpages = {16},
location = {Montreal, Canada},
series = {SSYM'09}
}
@inproceedings{elliott2018checkedc,
  author={Elliott, Archibald Samuel and Ruef, Andrew and Hicks, Michael and Tarditi, David},
  booktitle={2018 IEEE Cybersecurity Development (SecDev)}, 
  title={Checked C: Making C Safe by Extension}, 
  year={2018},
  volume={},
  number={},
  pages={53-60},
  doi={10.1109/SecDev.2018.00015}
}
@inproceedings{li2022formalcheckedc,
  author={Li, Liyi and Liu, Yiyun and Postol, Deena and Lampropoulos, Leonidas and Van Horn, David and Hicks, Michael},
  booktitle={2022 IEEE 35th Computer Security Foundations Symposium (CSF)}, 
  title={A Formal Model of Checked C}, 
  year={2022},
  volume={},
  number={},
  pages={49-63},
  doi={10.1109/CSF54842.2022.9919657}
}
@inproceedings{younan2010paricheck,
author = {Younan, Yves and Philippaerts, Pieter and Cavallaro, Lorenzo and Sekar, R. and Piessens, Frank and Joosen, Wouter},
title = {PAriCheck: An Efficient Pointer Arithmetic Checker for C Programs},
year = {2010},
isbn = {9781605589367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1755688.1755707},
doi = {10.1145/1755688.1755707},
abstract = {Buffer overflows are still a significant problem in programs written in C and C++. In this paper we present a bounds checker, called PAriCheck, that inserts dynamic runtime checks to ensure that attackers are not able to abuse buffer overflow vulnerabilities. The main approach is based on checking pointer arithmetic rather than pointer dereferences when performing bounds checks. The checks are performed by assigning a unique label to each object and ensuring that the label is associated with each memory location that the object inhabits. Whenever pointer arithmetic occurs, the label of the base location is compared to the label of the resulting arithmetic. If the labels differ, an out-of-bounds calculation has occurred. Benchmarks show that PAriCheck has a very low performance overhead compared to similar bounds checkers. This paper demonstrates that using bounds checkers for programs or parts of programs running on high-security production systems is a realistic possibility.},
booktitle = {Proceedings of the 5th ACM Symposium on Information, Computer and Communications Security},
pages = {145–156},
numpages = {12},
keywords = {bounds checking, buffer overflows},
location = {Beijing, China},
series = {ASIACCS '10}
}
@article{jung2021pico,
author = {Jung, Tina and Ritter, Fabian and Hack, Sebastian},
title = {PICO: A Presburger In-Bounds Check Optimization for Compiler-Based Memory Safety Instrumentations},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3460434},
doi = {10.1145/3460434},
abstract = {Memory safety violations such as buffer overflows are a threat to security to this day. A common solution to ensure memory safety for C is code instrumentation. However, this often causes high execution-time overhead and is therefore rarely used in production.Static analyses can reduce this overhead by proving some memory accesses in bounds at compile time. In practice, however, static analyses may fail to verify in-bounds accesses due to over-approximation. Therefore, it is important to additionally optimize the checks that reside in the program.In this article, we present PICO, an approach to eliminate and replace in-bounds checks. PICO exactly captures the spatial memory safety of accesses using Presburger formulas to either verify them statically or substitute existing checks with more efficient ones. Thereby, PICO can generate checks of which each covers multiple accesses and place them at infrequently executed locations.We evaluate our LLVM-based PICO prototype with the well-known SoftBound instrumentation on SPEC benchmarks commonly used in related work. PICO reduces the execution-time overhead introduced by SoftBound by 36\% on average (and the code-size overhead by 24\%). Our evaluation shows that the impact of substituting checks dominates that of removing provably redundant checks.},
journal = {ACM Trans. Archit. Code Optim.},
month = {jul},
articleno = {45},
numpages = {27},
keywords = {Presburger, spatial memory safety, Optimization, C language, LLVM}
}
@inproceedings{kwon2013lowfat,
author = {Kwon, Albert and Dhawan, Udit and Smith, Jonathan M. and Knight, Thomas F. and DeHon, Andre},
title = {Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-Based Security},
year = {2013},
isbn = {9781450324779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2508859.2516713},
doi = {10.1145/2508859.2516713},
abstract = {Referencing outside the bounds of an array or buffer is a common source of bugs and security vulnerabilities in today's software. We can enforce spatial safety and eliminate these violations by inseparably associating bounds with every pointer (fat pointer) and checking these bounds on every memory access. By further adding hardware-managed tags to the pointer, we make them unforgeable. This, in turn, allows the pointers to be used as capabilities to facilitate fine-grained access control and fast security domain crossing. Dedicated checking hardware runs in parallel with the processor's normal datapath so that the checks do not slow down processor operation (0\% runtime overhead). To achieve the safety of fat pointers without increasing program state, we compactly encode approximate base and bound pointers along with exact address pointers for a 46b address space into one 64-bit word with a worst-case memory overhead of 3\%. We develop gate-level implementations of the logic for updating and validating these compact fat pointers and show that the hardware requirements are low and the critical paths for common operations are smaller than processor ALU operations. Specifically, we show that the fat-pointer check and update operations can run in a 4 ns clock cycle on a Virtex 6 (40nm) implementation while only using 1100 6-LUTs or about the area of a double-precision, floating-point adder.},
booktitle = {Proceedings of the 2013 ACM SIGSAC Conference on Computer \& Communications Security},
pages = {721–732},
numpages = {12},
keywords = {spatial confinement, capabilities, memory safety, processor, security, fat pointer},
location = {Berlin, Germany},
series = {CCS '13}
}
@article{dhumbumroong2020boundwarden,
title = {BoundWarden: Thread-enforced spatial memory safety through compile-time transformations},
journal = {Science of Computer Programming},
volume = {198},
pages = {102519},
year = {2020},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2020.102519},
url = {https://www.sciencedirect.com/science/article/pii/S0167642320301271},
author = {Dhumbumroong, Smith and Piromsopa, Krerk},
keywords = {Spatial memory safety, Buffer overflows, Concurrent monitoring, Compile-time transformation, Bound checking thread},
abstract = {This paper presents BoundWarden, a novel spatial memory safety enforcement approach that utilizes a combination of compile-time transformation and runtime concurrent monitoring techniques. The compiler extension component of BoundWarden transparently instruments source code of C programs with the code that allows the runtime component of BoundWarden to comprehensively detect and prevent buffer overflow and other out-of-bound errors in buffers on the stack, heap, as well as BSS and data segments of memory. To reduce runtime overhead of bound checking, the runtime component of BoundWarden leverages the ubiquity of multi-core processors by offloading most of the work to a dedicated bound checking thread, which is responsible for performing bound checking and managing metadata. To preserve memory layout and maintain compatibility with existing libraries and binaries, BoundWarden stores the base and the bound of buffers in a separated dedicated bound table. Experiments showed that the prototype of BoundWarden is effective at enforcing spatial memory safety by successfully passing all 850 tests of RIPE test suite, and 94\% of NIST's SARD test suite 89, while the results from the Olden benchmark suite showed that on average BoundWarden introduced roughly 1.85x overhead, compared to the uninstrumented code.}
}
@article{saileshwar2022heapcheck,
author = {Saileshwar, Gururaj and Boivie, Rick and Chen, Tong and Segal, Benjamin and Buyuktosunoglu, Alper},
title = {HeapCheck: Low-Cost Hardware Support for Memory Safety},
year = {2022},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1544-3566},
url = {https://doi.org/10.1145/3495152},
doi = {10.1145/3495152},
abstract = {Programs written in C/C++ are vulnerable to memory-safety errors like buffer-overflows and use-after-free. While several mechanisms to detect such errors have been previously proposed, they suffer from a variety of drawbacks, including poor performance, imprecise or probabilistic detection of errors, or requiring invasive changes to the ISA, binary-layout, or source-code that results in compatibility issues. As a result, memory-safety errors continue to be hard to detect and a principal cause of security problems.In this work, we present a minimally invasive and low-cost hardware-based memory-safety checking framework for detecting out-of-bounds accesses and use-after-free errors. The key idea of our mechanism is to re-purpose some of the “unused bits” in a pointer in 64-bit architectures to store an index into a bounds information table that can be used to catch out-bounds errors and use-after-free errors without any change to the binary layout. Using this memory-safety checking framework, we enable HeapCheck, a design for detecting Out-of-bounds and Use-after-free accesses for heap-objects, that are responsible for the majority of memory-safety errors in the wild. Our evaluations using C/C++ SPEC CPU 2017 workloads on Gem5 show that our solution incurs 1.5\% slowdown on average, using an 8 KB on-chip SRAM cache for caching bounds-information. Our mechanism allows detection of out-of-bounds errors in user-code as well as in unmodified shared-library functions. Our mechanism has detected out-of-bounds accesses in 87 lines of code in the SPEC CPU 2017 benchmarks, primarily in Glibc v2.27 functions, that, to our knowledge, have not been previously detected even with popular tools like Address Sanitizer.},
journal = {ACM Trans. Archit. Code Optim.},
month = {jan},
articleno = {10},
numpages = {24},
keywords = {Memory safety, hardware bounds checking, software security}
}
@article{chen2023flexpointer,
author = {Chen, Dongwei and Tong, Dong and Yang, Chun and Yi, Jiangfang and Cheng, Xu},
title = {FlexPointer: Fast Address Translation Based on Range TLB and Tagged Pointers},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1544-3566},
url = {https://doi.org/10.1145/3579854},
doi = {10.1145/3579854},
abstract = {Page-based virtual memory relies on TLBs to accelerate the address translation. Nowadays, the gap between application workloads and the capacity of TLB continues to grow, bringing many costly TLB misses and making the TLB a performance bottleneck. Previous studies seek to narrow the gap by exploiting the contiguity of physical pages. One promising solution is to group pages that are both virtually and physically contiguous into a memory range. Recording range translations can greatly increase the TLB reach, but ranges are also hard to index because they have arbitrary bounds. The processor has to compare against all the boundaries to determine which range an address falls in, which restricts the usage of memory ranges. In this article, we propose a tagged-pointer-based scheme, FlexPointer, to solve the range indexing problem. The core insight of FlexPointer is that large memory objects are rare, so we can create memory ranges based on such objects and assign each of them a unique ID. With the range ID integrated into pointers, we can index the range TLB with IDs and greatly simplify its structure. Moreover, because the ID is stored in the unused bits of a pointer and is not manipulated by the address generation, we can shift the range lookup to an earlier stage, working in parallel with the address generation. According to our trace-based simulation results, FlexPointer can reduce nearly all the L1 TLB misses, and page walks for a variety of memory-intensive workloads. Compared with a 4K-page baseline system, FlexPointer shows a 14\% performance improvement on average and up to 2.8x speedup in the best case. For other workloads, FlexPointer shows no performance degradation.},
journal = {ACM Trans. Archit. Code Optim.},
month = {mar},
articleno = {30},
numpages = {24},
keywords = {Tagged pointer, TLB reach, address translation}
}
@inproceedings{shankaranarayana2023tailcheck,
  title={TAILCHECK: A Lightweight Heap Overflow Detection Mechanism with Page Protection and Tagged Pointers},
  author={Amogha Udupa Shankaranarayana and Gopal Raveendra Soori and Michael Ferdman and Dongyoon Lee},
  year={2023}
}
@article{kim2023whistle,
  title={WHISTLE: CPU Abstractions for Hardware and Software Memory Safety Invariants},
  author={Sungkeun Kim and Farabi Mahmud and Jiayi Huang and Pritam Majumder and Chia-che Tsai and Abdullah Muzahid and Eun Jung Kim},
  journal={IEEE Transactions on Computers},
  year={2023},
  volume={72},
  pages={811-825}
}
@inproceedings{nam2019framer,
author = {Nam, Myoung Jin and Akritidis, Periklis and Greaves, David J},
title = {FRAMER: A Tagged-Pointer Capability System with Memory Safety Applications},
year = {2019},
isbn = {9781450376280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3359789.3359799},
doi = {10.1145/3359789.3359799},
abstract = {Security mechanisms for systems programming languages, such as fine-grained memory protection for C/C++, authorize operations at runtime using access rights associated with objects and pointers. The cost of such fine-grained capability-based security models is dominated by metadata updates and lookups, making efficient metadata management the key for minimizing performance impact. Existing approaches reduce metadata management overheads by sacrificing precision, breaking binary compatibility by changing object memory layout, or wasting space with excessive alignment or large shadow memory spaces.We propose FRAMER, a capability framework with object granularity. Its sound and deterministic per-object metadata management mechanism enables direct access to metadata by calculating their location from a tagged pointer to the object and a compact supplementary table. This may improve the performance of memory safety, type safety, thread safety and garbage collection, or any solution that needs to map pointers to metadata. FRAMER improves over previous solutions by simultaneously (1) providing a novel encoding that derives the location of per-object metadata with low memory overhead and without any assumption of objects' alignment or size, (2) offering flexibility in metadata placement and size, (3) saving space by removing any padding or re-alignment, and (4) avoiding internal object memory layout changes. We evaluate FRAMER with a use case on memory safety.},
booktitle = {Proceedings of the 35th Annual Computer Security Applications Conference},
pages = {612–626},
numpages = {15},
keywords = {security, memory safety, LLVM, tagged pointers, object-capability model, bounds checking},
location = {San Juan, Puerto Rico, USA},
series = {ACSAC '19}
}
@article{zhou2023fatptrs,
author = {Zhou, Jie and Criswell, John and Hicks, Michael},
title = {Fat Pointers for Temporal Memory Safety of C},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3586038},
doi = {10.1145/3586038},
abstract = {Temporal memory safety bugs, especially use-after-free and double free bugs, pose a major security threat to C programs. Real-world exploits utilizing these bugs enable attackers to read and write arbitrary memory locations, causing disastrous violations of confidentiality, integrity, and availability. Many previous solutions retrofit temporal memory safety to C, but they all either incur high performance overhead and/or miss detecting certain types of temporal memory safety bugs. In this paper, we propose a temporal memory safety solution that is both efficient and comprehensive. Specifically, we extend Checked C, a spatially-safe extension to C, with temporally-safe pointers. These are implemented by combining two techniques: fat pointers and dynamic key-lock checks. We show that the fat-pointer solution significantly improves running time and memory overhead compared to the disjoint-metadata approach that provides the same level of protection. With empirical program data and hands-on experience porting real-world applications, we also show that our solution is practical in terms of backward compatibility---one of the major complaints about fat pointers.},
journal = {Proc. ACM Program. Lang.},
month = {apr},
articleno = {86},
numpages = {32},
keywords = {Fat Pointers, Temporal Memory Safety, Checked C}
}
@inproceedings{jim2002cyclone,
  title={Cyclone: A Safe Dialect of C},
  author={Trevor Jim and J. Gregory Morrisett and Dan Grossman and Michael W. Hicks and James Cheney and Yanling Wang},
  booktitle={USENIX Annual Technical Conference, General Track},
  year={2002}
}
@article{elliott2015guilt,
  title={Guilt free ivory},
  author={Trevor Elliott and Lee Pike and Simon Winwood and Patrick C. Hickey and James Bielman and Jamey Sharp and Eric L. Seidel and John Launchbury},
  journal={Proceedings of the 2015 ACM SIGPLAN Symposium on Haskell},
  year={2015}
}
@inproceedings{west2005cuckoo,
  title={Cuckoo: a Language for Implementing Memory- and Thread-safe System Services},
  author={Richard West and Gary T. Wong},
  booktitle={International Conference on Programming Languages and Compilers},
  year={2005}
}
@article{weis2019fyr,
  title={Fyr: a memory-safe and thread-safe systems programming language},
  author={Torben Weis and Marian Waltereit and Maximilian Uphoff},
  journal={Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
  year={2019}
}
@inproceedings{benoit2019uniqueness,
  title={Uniqueness Types for Efficient and Verifiable Aliasing-Free Embedded Systems Programming},
  author={Tuur Benoit and Bart Jacobs},
  booktitle={International Conference on Integrated Formal Methods},
  year={2019}
}
@inproceedings{bond2017vale,
author = {Barry Bond and Chris Hawblitzel and Manos Kapritsos and K. Rustan M. Leino and Jacob R. Lorch and Bryan Parno and Ashay Rane and Srinath Setty and Laure Thompson},
title = {Vale: Verifying {High-Performance} Cryptographic Assembly Code},
booktitle = {26th USENIX Security Symposium (USENIX Security 17)},
year = {2017},
isbn = {978-1-931971-40-9},
address = {Vancouver, BC},
pages = {917--934},
url = {https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/bond},
publisher = {USENIX Association},
month = aug,
}
@inproceedings{almeida2017jasmin,
author = {Almeida, Jos\'{e} Bacelar and Barbosa, Manuel and Barthe, Gilles and Blot, Arthur and Gr\'{e}goire, Benjamin and Laporte, Vincent and Oliveira, Tiago and Pacheco, Hugo and Schmidt, Benedikt and Strub, Pierre-Yves},
title = {Jasmin: High-Assurance and High-Speed Cryptography},
year = {2017},
isbn = {9781450349468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133956.3134078},
doi = {10.1145/3133956.3134078},
abstract = {Jasmin is a framework for developing high-speed and high-assurance cryptographic software. The framework is structured around the Jasmin programming language and its compiler. The language is designed for enhancing portability of programs and for simplifying verification tasks. The compiler is designed to achieve predictability and efficiency of the output code (currently limited to x64 platforms), and is formally verified in the Coq proof assistant. Using the supercop framework, we evaluate the Jasmin compiler on representative cryptographic routines and conclude that the code generated by the compiler is as efficient as fast, hand-crafted, implementations. Moreover, the framework includes highly automated tools for proving memory safety and constant-time security (for protecting against cache-based timing attacks). We also demonstrate the effectiveness of the verification tools on a large set of cryptographic routines.},
booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1807–1823},
numpages = {17},
keywords = {verified compiler, cryptographic implementations, constant-time security, safety},
location = {Dallas, Texas, USA},
series = {CCS '17}
}
@article{watt2019ctwasm,
author = {Watt, Conrad and Renner, John and Popescu, Natalie and Cauligi, Sunjay and Stefan, Deian},
title = {CT-Wasm: Type-Driven Secure Cryptography for the Web Ecosystem},
year = {2019},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {POPL},
url = {https://doi.org/10.1145/3290390},
doi = {10.1145/3290390},
abstract = {A significant amount of both client and server-side cryptography is implemented in JavaScript. Despite widespread concerns about its security, no other language has been able to match the convenience that comes from its ubiquitous support on the "web ecosystem" - the wide variety of technologies that collectively underpins the modern World Wide Web. With the introduction of the new WebAssembly bytecode language (Wasm) into the web ecosystem, we have a unique opportunity to advance a principled alternative to existing JavaScript cryptography use cases which does not compromise this convenience. We present Constant-Time WebAssembly (CT-Wasm), a type-driven, strict extension to WebAssembly which facilitates the verifiably secure implementation of cryptographic algorithms. CT-Wasm's type system ensures that code written in CT-Wasm is both information flow secure and resistant to timing side channel attacks; like base Wasm, these guarantees are verifiable in linear time. Building on an existing Wasm mechanization, we mechanize the full CT-Wasm specification, prove soundness of the extended type system, implement a verified type checker, and give several proofs of the language's security properties. We provide two implementations of CT-Wasm: an OCaml reference interpreter and a native implementation for Node.js and Chromium that extends Google's V8 engine. We also implement a CT-Wasm to Wasm rewrite tool that allows developers to reap the benefits of CT-Wasm's type system today, while developing cryptographic algorithms for base Wasm environments. We evaluate the language, our implementations, and supporting tools by porting several cryptographic primitives - Salsa20, SHA-256, and TEA - and the full TweetNaCl library. We find that CT-Wasm is fast, expressive, and generates code that we experimentally measure to be constant-time.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {77},
numpages = {29},
keywords = {constant-time, cryptography, WebAssembly, information flow control}
}
@article{kuepper2023cryptopt,
author = {Kuepper, Joel and Erbsen, Andres and Gross, Jason and Conoly, Owen and Sun, Chuyue and Tian, Samuel and Wu, David and Chlipala, Adam and Chuengsatiansup, Chitchanok and Genkin, Daniel and Wagner, Markus and Yarom, Yuval},
title = {CryptOpt: Verified Compilation with Randomized Program Search for Cryptographic Primitives},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {PLDI},
url = {https://doi.org/10.1145/3591272},
doi = {10.1145/3591272},
abstract = {Most software domains rely on compilers to translate high-level code to multiple different machine languages, with performance not too much worse than what developers would have the patience to write directly in assembly language. However, cryptography has been an exception, where many performance-critical routines have been written directly in assembly (sometimes through metaprogramming layers). Some past work has shown how to do formal verification of that assembly, and other work has shown how to generate C code automatically along with formal proof, but with consequent performance penalties vs. the best- known assembly. We present CryptOpt, the first compilation pipeline that specializes high-level cryptographic functional programs into assembly code significantly faster than what GCC or Clang produce, with mechanized proof (in Coq) whose final theorem statement mentions little beyond the input functional program and the operational semantics of x86-64 assembly. On the optimization side, we apply randomized search through the space of assembly programs, with repeated automatic benchmarking on target CPUs. On the formal-verification side, we connect to the Fiat Cryptography framework (which translates functional programs into C-like IR code) and extend it with a new formally verified program-equivalence checker, incorporating a modest subset of known features of SMT solvers and symbolic-execution engines. The overall prototype is quite practical, e.g. producing new fastest-known implementations of finite-field arithmetic for both Curve25519 (part of the TLS standard) and the Bitcoin elliptic curve secp256k1 for the Intel 12𝑡ℎ and 13𝑡ℎ generations.},
journal = {Proc. ACM Program. Lang.},
month = {jun},
articleno = {158},
numpages = {25},
keywords = {assembly, search-based software engineering, elliptic-curve cryptography}
}
@inproceedings{abate2021faandrc,
author="Abate, Carmine
and Busi, Matteo
and Tsampas, Stelios",
editor="Oh, Hakjoo",
title="Fully Abstract and Robust Compilation",
booktitle="Programming Languages and Systems",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="83--101",
abstract="The most prominent formal criterion for secure compilation is full abstraction, the preservation and reflection of contextual equivalence. Recent work introduced robust compilation, defined as the preservation of robust satisfaction of hyperproperties, i.e., their satisfaction against arbitrary attackers. In this paper, we initially set out to compare these two approaches to secure compilation. To that end, we provide an exact description of the hyperproperties that are robustly satisfied by programs compiled with a fully abstract compiler, and show that they can be meaningless or trivial. We then propose a novel criterion for secure compilation formulated in the framework of Mathematical Operational Semantics (MOS), guaranteeing both full abstraction and the preservation of robust satisfaction of hyperproperties in a more sensible manner.",
isbn="978-3-030-89051-3"
}
@inbook{abadi1999fullabstraction,
author="Abadi, Mart{\'i}n",
editor="Vitek, Jan
and Jensen, Christian D.",
title="Protection in Programming-Language Translations",
bookTitle="Secure Internet Programming: Security Issues for Mobile and Distributed Objects",
year="1999",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="19--34",
abstract="We discuss abstractions for protection and the correctness of their implementations. Relying on the concept of full abstraction, we consider two examples: (1) the translation of Java classes to an intermediate bytecode language, and (2) in the setting of the pi calculus, the implementation of private channels in terms of cryptographic operations.",
isbn="978-3-540-48749-4",
doi="10.1007/3-540-48749-2_2",
url="https://doi.org/10.1007/3-540-48749-2_2"
}
@inproceedings{watanabe2002modl,
  title={Well-behaved Translations between Structural Operational Semantics},
  author={Hiroshi Watanabe},
  booktitle={International Workshop on Coalgebraic Methods in Computer Science},
  year={2002}
}
@article{tsampas2020catsc,
  title={A categorical approach to secure compilation},
  author={Stelios Tsampas and Andreas Nuyts and Dominique Devriese and Frank Piessens},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.03557}
}
@article{patterson2019next700,
author = {Patterson, Daniel and Ahmed, Amal},
title = {The next 700 Compiler Correctness Theorems (Functional Pearl)},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {ICFP},
url = {https://doi.org/10.1145/3341689},
doi = {10.1145/3341689},
abstract = {Compiler correctness is an old problem, with results stretching back beyond the last half-century. Founding the field, John McCarthy and James Painter set out to build a "completely trustworthy compiler". And yet, until quite recently, even despite truly impressive verification efforts, the theorems being proved were only about the compilation of whole programs, a theoretically quite appealing but practically unrealistic simplification. For a compiler correctness theorem to assure complete trust, the theorem must reflect the reality of how the compiler will be used. There has been much recent work on more realistic "compositional" compiler correctness aimed at proving correct compilation of components while supporting linking with components compiled from different languages using different compilers. However, the variety of theorems, stated in remarkably different ways, raises questions about what researchers even mean by a "compiler is correct." In this pearl, we develop a new framework with which to understand compiler correctness theorems in the presence of linking, and apply it to understanding and comparing this diversity of results. In doing so, not only are we better able to assess their relative strengths and weaknesses, but gain insight into what we as a community should expect from compiler correctness theorems of the future.},
journal = {Proc. ACM Program. Lang.},
month = {jul},
articleno = {85},
numpages = {29},
keywords = {compilers, verification}
}
@article{vu2021reconciling,
  title={Reconciling optimization with secure compilation},
  author={Son Tuan Vu and Albert Cohen and Arnaud De Grandmaison and Christophe Guillon and Karine Heydemann},
  journal={Proceedings of the ACM on Programming Languages},
  year={2021},
  volume={5},
  pages={1 - 30}
}
@article{10.1145/315253.314414,
author = {Cooper, Keith D. and Schielke, Philip J. and Subramanian, Devika},
title = {Optimizing for Reduced Code Space Using Genetic Algorithms},
year = {1999},
issue_date = {July 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/315253.314414},
doi = {10.1145/315253.314414},
abstract = {Code space is a critical issue facing designers of software for embedded systems. Many traditional compiler optimizations are designed to reduce the execution time of compiled code, but not necessarily the size of the compiled code. Further, different results can be achieved by running some optimizations more than once and changing the order in which optimizations are applied. Register allocation only complicates matters, as the interactions between different optimizations can cause more spill code to be generated. The compiler for embedded systems, then, must take care to use the best sequence of optimizations to minimize code space.Since much of the code for embedded systems is compiled once and then burned into ROM, the software designer will often tolerate much longer compile times in the hope of reducing the size of the compiled code. We take advantage of this by using a genetic algorithm to find optimization sequences that generate small object codes. The solutions generated by this algorithm are compared to solutions found using a fixed optimization sequence and solutions found by testing random optimization sequences. Based on the results found by the genetic algorithm, a new fixed sequence is developed to reduce code size. Finally, we explore the idea of using different optimization sequences for different modules and functions of the same program.},
journal = {SIGPLAN Not.},
month = {may},
pages = {1–9},
numpages = {9}
}

@inproceedings{cooper1999geneticphases,
author = {Cooper, Keith D. and Schielke, Philip J. and Subramanian, Devika},
title = {Optimizing for Reduced Code Space Using Genetic Algorithms},
year = {1999},
isbn = {1581131364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/314403.314414},
doi = {10.1145/314403.314414},
abstract = {Code space is a critical issue facing designers of software for embedded systems. Many traditional compiler optimizations are designed to reduce the execution time of compiled code, but not necessarily the size of the compiled code. Further, different results can be achieved by running some optimizations more than once and changing the order in which optimizations are applied. Register allocation only complicates matters, as the interactions between different optimizations can cause more spill code to be generated. The compiler for embedded systems, then, must take care to use the best sequence of optimizations to minimize code space.Since much of the code for embedded systems is compiled once and then burned into ROM, the software designer will often tolerate much longer compile times in the hope of reducing the size of the compiled code. We take advantage of this by using a genetic algorithm to find optimization sequences that generate small object codes. The solutions generated by this algorithm are compared to solutions found using a fixed optimization sequence and solutions found by testing random optimization sequences. Based on the results found by the genetic algorithm, a new fixed sequence is developed to reduce code size. Finally, we explore the idea of using different optimization sequences for different modules and functions of the same program.},
booktitle = {Proceedings of the ACM SIGPLAN 1999 Workshop on Languages, Compilers, and Tools for Embedded Systems},
pages = {1–9},
numpages = {9},
location = {Atlanta, Georgia, USA},
series = {LCTES '99}
}
@inproceedings{kulkarni2006exhaustivephase,
  author={Kulkarni, P.A. and Whalley, D.B. and Tyson, G.S. and Davidson, J.W.},
  booktitle={International Symposium on Code Generation and Optimization (CGO'06)}, 
  title={Exhaustive optimization phase order space exploration}, 
  year={2006},
  volume={},
  number={},
  pages={13 pp.-318},
  doi={10.1109/CGO.2006.15}
}
@misc{androidstudio,
  title = {{Android Studio} Webpage},
  author = {Google},
  howpublished = {\url{https://developer.android.com/}},
  note = {Accessed: 2023-05-30}
}
@misc{googlev8,
  title = {{V8} Javascript Engine},
  author = {Google},
  year = 2008,
  howpublished = {\url{https://v8.dev/blog/10-years}},
  note = {Accessed: 2023-05-30}
}
@inproceedings{lattner2004llvm,
     Author  = {Chris Lattner and Vikram Adve},
     Title = {{LLVM}: A Compilation Framework for Lifelong Program 
Analysis and Transformation},
     Booktitle = CGO,
     Address = {San Jose, CA, USA},
     Month = {Mar},
     Year  = {2004},
     pages       = {75--88},
}
@article{wegman1991ccp,
author = {Wegman, Mark N. and Zadeck, F. Kenneth},
title = {Constant Propagation with Conditional Branches},
year = {1991},
issue_date = {April 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/103135.103136},
doi = {10.1145/103135.103136},
abstract = {Constant propagation is a well-known global flow analysis problem. The goal of constant propagation is to discover values that are constant on all possible executions of a program and to propagate these constant values as far foward through the program as possible. Expressions whose operands are all constants can be evaluated at compile time and the results propagated further. Using the algorithms presented in this paper can produce smaller and faster compiled programs. The same algorithms can be used for other kinds of analyses (e.g., type of determination). We present four algorithms in this paper, all conservitive in the sense that all constants may not be found, but each constant found is constant over all possible executions of the program. These algorithms are among the simplest, fastest, and most powerful global constant propagation algorithms known. We also present a new algorithm that performs a form of interprocedural data flow analysis in which aliasing information is gathered in conjunction with constant progagation. Several variants of this algorithm are considered.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {apr},
pages = {181–210},
numpages = {30},
keywords = {constant propagation, abstract interpretation, interprocedural analysis, type determination, static single assignment form, control flow graph, code optimization, procedure integration}
}
@article{manjikian1997fusion,
  author={Manjikian, N. and Abdelrahman, T.S.},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Fusion of loops for parallelism and locality}, 
  year={1997},
  volume={8},
  number={2},
  pages={193-209},
  doi={10.1109/71.577265}
}
@misc{canetti2006univcomp,
      author = {Ran Canetti and Yevgeniy Dodis and Rafael Pass and Shabsi Walfish},
      title = {Universally Composable Security with Global Setup},
      howpublished = {Cryptology ePrint Archive, Paper 2006/432},
      year = {2006},
      note = {\url{https://eprint.iacr.org/2006/432}},
      url = {https://eprint.iacr.org/2006/432}
}
@inproceedings {mccullough2012compo,
author = {D. McCullough},
booktitle = {2012 IEEE Symposium on Security and Privacy},
title = {Noninterference and the Composability of Security Properties},
year = {1988},
volume = {},
issn = {1540-7993},
pages = {177},
abstract = {In this paper, I discuss the problem of composability of multi-level security properties, particularly the noninterference property and some of its generalizations. Through examples I attempt to show that some of these security properties do not compose-it is possible to connect two systems, both of which are judged to be secure, such that the composite system is not secure. Although the examples are "cooked up" to make a point, there is nothing especially tricky done; I make sure that outputs from one system become inputs to the other machine at the same security level, and use a standard notion of parallel composition of systems (see [Hoare 85]).},
doi = {10.1109/SECPRI.1988.8110},
url = {https://doi.ieeecomputersociety.org/10.1109/SECPRI.1988.8110},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {apr}
}
@inproceedings{fabian2022automatic,
 author    = { Xaver Fabian and 
               Marco Patrignani and 
               Marco Guarnieri
              },
  title     = {Automatic Detection of Speculative Execution Combinations},
  booktitle = {Proceedings of the 29th ACM Conference on Computer and Communications Security},
  year      = {2022},
  series={CCS 2022},
  publisher={ACM}
}
@inproceedings{kocher1996timing,
author="Kocher, Paul C.",
editor="Koblitz, Neal",
title="Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems",
booktitle="Advances in Cryptology --- CRYPTO '96",
year="1996",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="104--113",
abstract="By carefully measuring the amount of time required to perform private key operations, attackers may be able to find fixed Diffie-Hellman exponents, factor RSA keys, and break other cryptosystems. Against a vulnerable system, the attack is computationally inexpensive and often requires only known ciphertext. Actual systems are potentially at risk, including cryptographic tokens, network-based cryptosystems, and other applications where attackers can make reasonably accurate timing measurements. Techniques for preventing the attack for RSA and Diffie-Hellman are presented. Some cryptosystems will need to be revised to protect against the attack, and new protocols and algorithms may need to incorporate measures to prevent timing attacks.",
isbn="978-3-540-68697-2"
}
@misc{mehmet2015getoff,
      author = {Mehmet Sinan Inci and Berk Gulmezoglu and Gorka Irazoqui and Thomas Eisenbarth and Berk Sunar},
      title = {Seriously, get off my cloud! Cross-VM RSA Key Recovery in a Public Cloud},
      howpublished = {Cryptology ePrint Archive, Paper 2015/898},
      year = {2015},
      note = {\url{https://eprint.iacr.org/2015/898}},
      url = {https://eprint.iacr.org/2015/898}
}
@inproceedings{aviram2010cloudtime,
author = {Aviram, Amittai and Hu, Sen and Ford, Bryan and Gummadi, Ramakrishna},
title = {Determinating Timing Channels in Compute Clouds},
year = {2010},
isbn = {9781450300896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866835.1866854},
doi = {10.1145/1866835.1866854},
abstract = {Timing side-channels represent an insidious security challenge for cloud computing, because: (a) massive parallelism in the cloud makes timing channels pervasive and hard to control; (b) timing channels enable one customer to steal information from another without leaving a trail or raising alarms; (c) only the cloud provider can feasibly detect and report such attacks, but the provider's incentives are not to; and (d) resource partitioning schemes for timing channel control undermine statistical sharing efficiency, and, with it, the cloud computing business model. We propose a new approach to timing channel control, using provider-enforced deterministic execution instead of resource partitioning to eliminate timing channels within a shared cloud domain. Provider-enforced determinism prevents execution timing from affecting the results of a compute task, however large or parallel, ensuring that a task's outputs leak no timing information apart from explicit timing inputs and total compute duration. Experiments with a prototype OS for deterministic cloud computing suggest that such an approach may be practical and efficient. The OS supports deterministic versions of familiar APIs such as processes, threads, shared memory, and file systems, and runs coarse-grained parallel tasks as efficiently and scalably as current timing channel-ridden systems.},
booktitle = {Proceedings of the 2010 ACM Workshop on Cloud Computing Security Workshop},
pages = {103–108},
numpages = {6},
keywords = {timing channels, cloud computing, deterministic parallelism},
location = {Chicago, Illinois, USA},
series = {CCSW '10}
}
@article{kumar2019cloudsecsurvey,
title = {On cloud security requirements, threats, vulnerabilities and countermeasures: A survey},
journal = {Computer Science Review},
volume = {33},
pages = {1-48},
year = {2019},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2019.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1574013718302065},
author = {Rakesh Kumar and Rinkaj Goyal},
keywords = {Cloud computing, Security in cloud, Cloud security trust model, Cloud security challenges, Cloud security requirements threats vulnerabilities countermeasures},
abstract = {The world is witnessing a phenomenal growth in the cloud enabled services and is expected to grow further with the improved technological innovations. However, the associated security and privacy challenges inhibit its widespread adoption, and therefore require further exploration. Researchers from academia, industry, and standards organizations have provided potential solutions to these challenges in the previously published studies. The narrative review presented in this survey, however, provides an integrationist end-to-end mapping of cloud security requirements, identified threats, known vulnerabilities, and recommended countermeasures, which seems to be not presented before at one place. Additionally, this study contributes towards identifying a unified taxonomy for security requirements, threats, vulnerabilities and countermeasures to carry out the proposed end-to-end mapping. Further, it highlights security challenges in other related areas like trust based security models, cloud-enabled applications of Big Data, Internet of Things (IoT), Software Defined Network (SDN) and Network Function Virtualization (NFV).}
}
@article{flowers2022zeroday,
  author={Flowers, Robert},
  journal={IEEE Access}, 
  title={A Zero-Day Cloud Timing Channel Attack}, 
  year={2022},
  volume={10},
  number={},
  pages={128177-128186},
  doi={10.1109/ACCESS.2022.3227420}
}
@article{atya2019catchme,
  author={Atya, Ahmed Osama Fathy and Qian, Zhiyun and Krishnamurthy, Srikanth V. and La Porta, Thomas and McDaniel, Patrick and Marvel, Lisa M.},
  journal={IEEE/ACM Transactions on Networking}, 
  title={Catch Me if You Can: A Closer Look at Malicious Co-Residency on the Cloud}, 
  year={2019},
  volume={27},
  number={2},
  pages={560-576},
  doi={10.1109/TNET.2019.2891528}
}
@inproceedings {venkatanathan2015placevul,
author = {Venkatanathan Varadarajan and Yinqian Zhang and Thomas Ristenpart and Michael Swift},
title = {A Placement Vulnerability Study in {Multi-Tenant} Public Clouds},
booktitle = {24th USENIX Security Symposium (USENIX Security 15)},
year = {2015},
isbn = {978-1-939133-11-3},
address = {Washington, D.C.},
pages = {913--928},
url = {https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/varadarajan},
publisher = {USENIX Association},
month = aug,
}
@inproceedings{lemay2021ccc,
author = {LeMay, Michael and Rakshit, Joydeep and Deutsch, Sergej and Durham, David M. and Ghosh, Santosh and Nori, Anant and Gaur, Jayesh and Weiler, Andrew and Sultana, Salmin and Grewal, Karanvir and Subramoney, Sreenivas},
title = {Cryptographic Capability Computing},
year = {2021},
isbn = {9781450385572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3466752.3480076},
doi = {10.1145/3466752.3480076},
abstract = {Capability architectures for memory safety have traditionally required expanding pointers and radically changing microarchitectural structures throughout processors, while only providing superficial hardening. We hence propose Cryptographic Capability Computing (C3) - the first memory safety mechanism that is stateless to avoid requiring extra metadata storage. C3 retains 64-bit pointer sizes providing legacy binary compatibility while imposing minimal touchpoints. Pointers are encrypted to unforgeably (within cryptographic bounds) reference each object. Data is encrypted even in caches and entangled with pointers for both spatial and temporal object-granular protection. Pointers become like unique keys for each allocation. C3 deploys a novel form of prediction for address translation that mitigates performance overheads even when addresses are partially encrypted. Use of a low-latency, low-area cipher from the NIST Lightweight Cryptography project avoids delaying loads by readying a data keystream by the time data is returned from the L1 cache. C3 is compatible with legacy binaries. Simulated performance overhead on SPEC CPU2006 is negligible with no memory overhead, which is a big leap forward compared to the overheads imposed by past memory safety approaches. C3 effectively replaces inefficient metadata with efficient cryptography.},
booktitle = {MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {253–267},
numpages = {15},
keywords = {memory safety, memory encryption, capabilities},
location = {Virtual Event, Greece},
series = {MICRO '21}
}
@article{devriese2018parametricity,
author = {Devriese, Dominique and Patrignani, Marco and Piessens, Frank},
title = {Parametricity versus the Universal Type},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {POPL},
url = {https://doi.org/10.1145/3158126},
doi = {10.1145/3158126},
abstract = {There has long been speculation in the scientific literature on how to dynamically enforce parametricity such as that yielded by System F. Almost 20 years ago, Sumii and Pierce proposed a formal compiler from System F into the cryptographic lambda calculus: an untyped lambda calculus extended with an idealised model of encryption. They conjectured that this compiler was fully abstract, i.e. that compiled terms are contextually equivalent if and only if the original terms were, a property that can be seen as a form of secure compilation. The conjecture has received attention in several other publications since then, but remains open to this day. More recently, several researchers have been looking at gradually-typed languages that extend System F. In this setting it is natural to wonder whether embedding System F into these gradually-typed languages preserves contextual equivalence and thus parametricity. In this paper, we answer both questions negatively. We provide a concrete counterexample: two System F terms whose contextual equivalence is not preserved by the Sumii-Pierce compiler, nor the embedding into the polymorphic blame calculus. This counterexample relies on the absence in System F of what we call a universal type, i.e., a type that all other types can be injected into and extracted from. As the languages in which System F is compiled have a universal type, the compilation cannot be fully abstract; this paper explains why. We believe this paper thus sheds light on recent results in the field of gradually typed languages and it provides a perspective for further research into secure compilation of polymorphic languages.},
journal = {Proc. ACM Program. Lang.},
month = {dec},
articleno = {38},
numpages = {23},
keywords = {sealing, parametricity, System F, fully abstract compilation, universal type}
}
@misc{doublefree-bluetooth,
  title = {{CVE}-2021-3564.},
  author = {BlockSec},
  howpublished = "Available from MITRE, {CVE-ID} {CVE}-2021-2564.",
  month= {may},
  year = {2021},
  url={http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-2564 },
  urldate={09.06.2023}
}
@misc{uninit-0,
  title = {{CVE}-2015-1770.},
  author = {Microsoft},
  howpublished = "Available from MITRE, {CVE-ID} {CVE}-2015-1770.",
  month = {feb},
  year = {2015},
  url = {http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-1770 },
  urldate = {09.06.2023}
}
@misc{uninit-1,
  title = {{CVE}-2011-0036.},
  author = {Microsoft},
  howpublished = "Available from MITRE, {CVE-ID} {CVE}-2011-0036.",
  month = {dec},
  year = {2010},
  url = {http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2011-0036 },
  urldate = {09.06.2023}
}
@misc{uninit-2,
  title = {{CVE}-2010-2557.},
  author = {Microsoft},
  howpublished = "Available from MITRE, {CVE-ID} {CVE}-2010-2557.",
  month = {nov},
  year = {2010},
  url = {http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2010-2557 },
  urldate = {09.06.2023}
}
@misc{uninit-3,
  title = {{CVE}-2011-0035.},
  author = {Microsoft},
  howpublished = "Available from MITRE, {CVE-ID} {CVE}-2011-0035.",
  month = {dec},
  year = {2010},
  url = {http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2011-0035 },
  urldate = {09.06.2023}
}
@misc{uninit-4,
  title = {{CVE}-2023-20892.},
  author = {VMWare},
  howpublished = "Available from MITRE, {CVE-ID} {CVE}-2023-20892.",
  month = {jun},
  year = {2023},
  url = {http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-20892 },
  urldate = {09.06.2023}
}
@article{click1995combining,
author = {Click, Cliff and Cooper, Keith D.},
title = {Combining Analyses, Combining Optimizations},
year = {1995},
issue_date = {March 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/201059.201061},
doi = {10.1145/201059.201061},
abstract = {Modern optimizing compilers use several passes over a program's intermediate representation to generate good code. Many of these optimizations exhibit a phase-ordering problem. Getting the best code may require iterating optimizations until a fixed point is reached. Combining these phases can lead to the discovery of more facts about the program, exposing more opportunities for optimization. This article presents a framework for describing optimizations. It shows how to combine two such frameworks and how to reason about the properties of the resulting framework. The structure of the frame work provides insight into when a combination yields better results. To make the ideas more concrete, this article presents a framework for combining constant propagation, value numbering, and unreachable-code elimination. It is an open question as to what other frameworks can be combined in this way.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {mar},
pages = {181–196},
numpages = {16},
keywords = {optimizing compilers, data-flow analysis, constant propagation, value numbering}
}
@manual{arm-refman,
  author       = {Arm},
  year         = {2020},
  title        = {Arm\textregistered A-profile Architecture Registers},
  howpublished = {\url{https://developer.arm.com/documentation/ddi0601/2023-06/AArch64-Registers/DIT--Data-Independent-Timing?lang=en}},
  version      = {2023-06},
  note         = {Accessed: 2023-06-09}
}
@manual{intel-refman,
  author = {Intel},
  month = {jun},
  year = {2023},
  title = {Intel\textsuperscript{TM} 64 and IA-32 Architectures Software Developer Manual},
  volume = {4},
  url = {https://cdrdv2.intel.com/v1/dl/getContent/671200},
  version = {335592},
  note = {Acccessed: 2023-06-09}
}
@manual{arm-morello,
  author       = {Arm},
  year         = {2022},
  title        = {Morello\textsuperscript{TM} for A-profile Architecture},
  url = {Arm Architecture Reference Manual Supplement Morello for A-profile Architecture},
  version      = {2022-01},
  note         = {Accessed: 2023-06-10}
}
@article{10.1145/2678373.2665740,
author = {Woodruff, Jonathan and Watson, Robert N.M. and Chisnall, David and Moore, Simon W. and Anderson, Jonathan and Davis, Brooks and Laurie, Ben and Neumann, Peter G. and Norton, Robert and Roe, Michael},
title = {The CHERI Capability Model: Revisiting RISC in an Age of Risk},
year = {2014},
issue_date = {June 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0163-5964},
url = {https://doi.org/10.1145/2678373.2665740},
doi = {10.1145/2678373.2665740},
abstract = {Motivated by contemporary security challenges, we reevaluate and refine capability-based addressing for the RISC era. We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection. We demonstrate that CHERI enables language memory model enforcement and fault isolation in hardware rather than software, and that the CHERI mechanisms are easily adopted by existing programs for efficient in-program memory safety. In contrast to past capability models, CHERI complements, rather than replaces, the ubiquitous page-based protection mechanism, providing a migration path towards deconflating data-structure protection and OS memory management. Furthermore, CHERI adheres to a strict RISC philosophy: it maintains a load-store architecture and requires only singlecycle instructions, and supplies protection primitives to the compiler, language runtime, and operating system. We demonstrate a mature FPGA implementation that runs the FreeBSD operating system with a full range of software and an open-source application suite compiled with an extended LLVM to use CHERI memory protection. A limit study compares published memory safety mechanisms in terms of instruction count and memory overheads. The study illustrates that CHERI is performance-competitive even while providing assurance and greater flexibility with simpler hardware},
journal = {SIGARCH Comput. Archit. News},
month = {jun},
pages = {457–468},
numpages = {12}
}

@inproceedings{woodruff2014CHERI,
author = {Woodruff, Jonathan and Watson, Robert N.M. and Chisnall, David and Moore, Simon W. and Anderson, Jonathan and Davis, Brooks and Laurie, Ben and Neumann, Peter G. and Norton, Robert and Roe, Michael},
title = {The CHERI Capability Model: Revisiting RISC in an Age of Risk},
year = {2014},
isbn = {9781479943944},
publisher = {IEEE Press},
abstract = {Motivated by contemporary security challenges, we reevaluate and refine capability-based addressing for the RISC era. We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection. We demonstrate that CHERI enables language memory model enforcement and fault isolation in hardware rather than software, and that the CHERI mechanisms are easily adopted by existing programs for efficient in-program memory safety. In contrast to past capability models, CHERI complements, rather than replaces, the ubiquitous page-based protection mechanism, providing a migration path towards deconflating data-structure protection and OS memory management. Furthermore, CHERI adheres to a strict RISC philosophy: it maintains a load-store architecture and requires only singlecycle instructions, and supplies protection primitives to the compiler, language runtime, and operating system. We demonstrate a mature FPGA implementation that runs the FreeBSD operating system with a full range of software and an open-source application suite compiled with an extended LLVM to use CHERI memory protection. A limit study compares published memory safety mechanisms in terms of instruction count and memory overheads. The study illustrates that CHERI is performance-competitive even while providing assurance and greater flexibility with simpler hardware},
booktitle = {Proceeding of the 41st Annual International Symposium on Computer Architecuture},
pages = {457–468},
numpages = {12},
location = {Minneapolis, Minnesota, USA},
series = {ISCA '14}
}
@inproceedings{azevedo2018meaningsofms,
author="Azevedo de Amorim, Arthur
and Hri{\c{t}}cu, C{\u{a}}t{\u{a}}lin
and Pierce, Benjamin C.",
editor="Bauer, Lujo
and K{\"u}sters, Ralf",
title="The Meaning of Memory Safety",
booktitle="Principles of Security and Trust",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="79--105",
abstract="We give a rigorous characterization of what it means for a programming language to be memory safe, capturing the intuition that memory safety supports local reasoning about state. We formalize this principle in two ways. First, we show how a small memory-safe language validates a noninterference property: a program can neither affect nor be affected by unreachable parts of the state. Second, we extend separation logic, a proof system for heap-manipulating programs, with a ``memory-safe variant'' of its frame rule. The new rule is stronger because it applies even when parts of the program are buggy or malicious, but also weaker because it demands a stricter form of separation between parts of the program state. We also consider a number of pragmatically motivated variations on memory safety and the reasoning principles they support. As an application of our characterization, we evaluate the security of a previously proposed dynamic monitor for memory safety of heap-allocated data.",
isbn="978-3-319-89722-6"
}
@inproceedings{maffeis2008code-carrying,
author = {Maffeis, Sergio and Abadi, Martín and Fournet, Cédric and Gordon, Andy},
title = {Code-Carrying Authorization},
booktitle = {13th European Symposium on Research in Computer Security, MÃ¡laga, Spain, October 6-8, 2008. Proceedings},
year = {2008},
month = {October},
abstract = {In authorization, there is often a wish to shift the burden of proof to those making requests, since they may have more resources and more specific knowledge to construct the required proofs. We introduce an extreme instance of this approach, which we call Code-Carrying Authorization (CCA). With CCA, access-control decisions can partly be delegated to untrusted code obtained at run-time. The dynamic verification of this code ensures the safety of authorization decisions. We define and study this approach in the setting of a higher-order spi calculus. The type system of this calculus provides the needed support for static and dynamic verification.},
publisher = {Springer Berlin Heidelberg},
url = {https://www.microsoft.com/en-us/research/publication/code-carrying-authorization/},
pages = {563-579},
volume = {5283},
isbn = {978-3-540-88312-8 (Print) 978-3-540-88313-5 (Online)},
edition = {13th European Symposium on Research in Computer Security, Málaga, Spain, October 6-8, 2008. Proceedings},
}
@article{gordon2003authenticity,
author = {Gordon, Andrew D. and Jeffrey, Alan},
title = {Authenticity by Typing for Security Protocols},
year = {2003},
issue_date = {July 2003},
publisher = {IOS Press},
address = {NLD},
volume = {11},
number = {4},
issn = {0926-227X},
abstract = {We propose a new method to check authenticity properties of cryptographic protocols. First, code up the protocol in the spi-calculus of Abadi and Gordon. Second, specify authenticity properties by annotating the code with correspondence assertions in the style of Woo and Lam. Third, figure out types for the keys, nonces, and messages of the protocol. Fourth, check that the spi-calculus code is well-typed according to a novel type and effect system presented in this paper. Our main theorem guarantees that any well-typed protocol is robustly safe, that is, its correspondence assertions are true in the presence of any opponent expressible in spi. It is feasible to apply this method by hand to several well-known cryptographic protocols. It requires little human effort per protocol, puts no bound on the size of the opponent, and requires no state space enumeration. Moreover, the types for protocol data provide some intuitive explanation of how the protocol works. This paper describes our method and gives some simple examples. Our method has led us to the independent rediscovery of flaws in existing protocols and to the design of improved protocols.},
journal = {J. Comput. Secur.},
month = {jul},
pages = {451–519},
numpages = {69}
}
@article{fournet2007authorization,
author = {Fournet, C\'{e}dric and Gordon, Andrew D. and Maffeis, Sergio},
title = {A Type Discipline for Authorization Policies},
year = {2007},
issue_date = {August 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {5},
issn = {0164-0925},
url = {https://doi.org/10.1145/1275497.1275500},
doi = {10.1145/1275497.1275500},
abstract = {Distributed systems and applications are often expected to enforce high-level authorization policies. To this end, the code for these systems relies on lower-level security mechanisms such as digital signatures, local ACLs, and encrypted communications. In principle, authorization specifications can be separated from code and carefully audited. Logic programs in particular can express policies in a simple, abstract manner.We consider the problem of checking whether a distributed implementation based on communication channels and cryptography complies with a logical authorization policy. We formalize authorization policies and their connection to code by embedding logical predicates and claims within a process calculus. We formulate policy compliance operationally by composing a process model of the distributed system with an arbitrary opponent process. Moreover, we propose a dependent type system for verifying policy compliance of implementation code. Using Datalog as an authorization logic, we show how to type several examples using policies and present a general schema for compiling policies.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {aug},
pages = {25–es},
numpages = {37},
keywords = {process calculus, spi calculus, Authorization, type systems}
}
@article{bengtson2011refine,
author = {Bengtson, Jesper and Bhargavan, Karthikeyan and Fournet, C\'{e}dric and Gordon, Andrew D. and Maffeis, Sergio},
title = {Refinement Types for Secure Implementations},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/1890028.1890031},
doi = {10.1145/1890028.1890031},
abstract = {We present the design and implementation of a typechecker for verifying security properties of the source code of cryptographic protocols and access control mechanisms. The underlying type theory is a λ-calculus equipped with refinement types for expressing pre- and post-conditions within first-order logic. We derive formal cryptographic primitives and represent active adversaries within the type theory. Well-typed programs enjoy assertion-based security properties, with respect to a realistic threat model including key compromise. The implementation amounts to an enhanced typechecker for the general-purpose functional language F#; typechecking generates verification conditions that are passed to an SMT solver. We describe a series of checked examples. This is the first tool to verify authentication properties of cryptographic protocols by typechecking their source code.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {feb},
articleno = {8},
numpages = {45}
}
@article{backes2014uniontyps,
 abstract = {We present a new type system for verifying the security of reference implementations of cryptographic protocols written in a core functional programming language. The type system combines prior work on refinement types, with union, intersection, and polymorphic types, and with the novel ability to reason statically about the disjointness of types. The increased expressivity enables the analysis of important protocol classes that were previously out of scope for the type-based analyses of reference protocol implementations. In particular, our types can statically characterize: (i) more usages of asymmetric cryptography, such as signatures of private data and encryptions of authenticated data; (ii) authenticity and integrity properties achieved by showing knowledge of secret data; (iii) applications based on zero-knowledge proofs. The type system comes with a mechanized proof of correctness and an efficient type-checker.},
 author = {Backes, Michael and Hriţcu, Cătălin and Maffei, Matteo},
 doi = {10.3233/jcs-130493},
 journal = {Journal of Computer Security},
 keywords = {},
 number = {2},
 pages = {301-353},
 title = {Union, intersection and refinement types and reasoning about type disjointness for secure protocol implementations},
 url = {https://doi.org/10.3233/jcs-130493},
 volume = {22},
 year = {2014}
}
@article{strydonck2019lincap,
author = {Van Strydonck, Thomas and Piessens, Frank and Devriese, Dominique},
title = {Linear Capabilities for Fully Abstract Compilation of Separation-Logic-Verified Code},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {ICFP},
url = {https://doi.org/10.1145/3341688},
doi = {10.1145/3341688},
abstract = {Separation logic is a powerful program logic for the static modular verification of imperative programs. However, dynamic checking of separation logic contracts on the boundaries between verified and untrusted modules is hard, because it requires one to enforce (among other things) that outcalls from a verified to an untrusted module do not access memory resources currently owned by the verified module. This paper proposes an approach to dynamic contract checking by relying on support for capabilities, a well-studied form of unforgeable memory pointers that enables fine-grained, efficient memory access control. More specifically, we rely on a form of capabilities called linear capabilities for which the hardware enforces that they cannot be copied. We formalize our approach as a fully abstract compiler from a statically verified source language to an unverified target language with support for linear capabilities. The key insight behind our compiler is that memory resources described by spatial separation logic predicates can be represented at run time by linear capabilities. The compiler is separation-logic-proof-directed: it uses the separation logic proof of the source program to determine how memory accesses in the source program should be compiled to linear capability accesses in the target program. The full abstraction property of the compiler essentially guarantees that compiled verified modules can interact with untrusted target language modules as if they were compiled from verified code as well.},
journal = {Proc. ACM Program. Lang.},
month = {jul},
articleno = {84},
numpages = {29},
keywords = {capabilities, verification, separation logic, fully abstract compilation}
}
@article{devriese2017modular,
  TITLE = {{Modular, Fully-abstract Compilation by Approximate Back-translation}},
  AUTHOR = {Dominique Devriese and Marco Patrignani and Frank Piessens and Steven Keuchel},
  URL = {https://lmcs.episciences.org/4011},
  DOI = {10.23638/LMCS-13(4:2)2017},
  JOURNAL = {{Logical Methods in Computer Science}},
  VOLUME = {{Volume 13, Issue 4}},
  YEAR = {2017},
  MONTH = Oct,
  KEYWORDS = {Computer Science - Programming Languages},
}
@inproceedings{10.1145/2784731.2784733,
author = {Bowman, William J. and Ahmed, Amal},
title = {Noninterference for Free},
year = {2015},
isbn = {9781450336697},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2784731.2784733},
doi = {10.1145/2784731.2784733},
abstract = {The dependency core calculus (DCC) is a framework for studying a variety of dependency analyses (e.g., secure information flow). The key property provided by DCC is noninterference, which guarantees that a low-level observer (attacker) cannot distinguish high-level (protected) computations. The proof of noninterference for DCC suggests a connection to parametricity in System F, which suggests that it should be possible to implement dependency analyses in languages with parametric polymorphism. We present a translation from DCC into Fω and prove that the translation preserves noninterference. To express noninterference in Fω, we define a notion of observer-sensitive equivalence that makes essential use of both first-order and higher-order polymorphism. Our translation provides insights into DCC's type system and shows how DCC can be implemented in a polymorphic language without loss of the noninterference (security) guarantees available in DCC. Our contributions include proof techniques that should be valuable when proving other secure compilation or full abstraction results.},
booktitle = {Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming},
pages = {101–113},
numpages = {13},
keywords = {information flow, secure compilation, dependency, parametricity, fully abstract compilation, logical relations, security, polymorphism, Noninterference},
location = {Vancouver, BC, Canada},
series = {ICFP 2015}
}

@article{bowman2015noninterference,
author = {Bowman, William J. and Ahmed, Amal},
title = {Noninterference for Free},
year = {2015},
issue_date = {September 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/2858949.2784733},
doi = {10.1145/2858949.2784733},
abstract = {The dependency core calculus (DCC) is a framework for studying a variety of dependency analyses (e.g., secure information flow). The key property provided by DCC is noninterference, which guarantees that a low-level observer (attacker) cannot distinguish high-level (protected) computations. The proof of noninterference for DCC suggests a connection to parametricity in System F, which suggests that it should be possible to implement dependency analyses in languages with parametric polymorphism. We present a translation from DCC into Fω and prove that the translation preserves noninterference. To express noninterference in Fω, we define a notion of observer-sensitive equivalence that makes essential use of both first-order and higher-order polymorphism. Our translation provides insights into DCC's type system and shows how DCC can be implemented in a polymorphic language without loss of the noninterference (security) guarantees available in DCC. Our contributions include proof techniques that should be valuable when proving other secure compilation or full abstraction results.},
journal = {SIGPLAN Not.},
month = {aug},
pages = {101–113},
numpages = {13},
keywords = {security, logical relations, polymorphism, fully abstract compilation, Noninterference, secure compilation, information flow, parametricity, dependency}
}
@inproceedings{ahmed2011equivcps,
author = {Ahmed, Amal and Blume, Matthias},
title = {An Equivalence-Preserving CPS Translation via Multi-Language Semantics},
year = {2011},
isbn = {9781450308656},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2034773.2034830},
doi = {10.1145/2034773.2034830},
abstract = {Language-based security relies on the assumption that all potential attacks follow the rules of the language in question. When programs are compiled into a different language, this is true only if the translation process preserves observational equivalence.To prove that a translation preserves equivalence, one must show that if two program fragments cannot be distinguished by any source context, then their translations cannot be distinguished by any target context. Informally, target contexts must be no more powerful than source contexts, i.e., for every target context there exists a source context that "behaves the same." This seems to amount to being able to "back-translate" arbitrary target terms. However, that is simply not viable for practical compilers where the target language is lower-level and, thus, contains expressions that have no source equivalent.In this paper, we give a CPS translation from a less expressive source language (STLC) to a more expressive target language (System F) and prove that the translation preserves observational equivalence. The key to our equivalence-preserving compilation is the choice of the right type translation: a source type σ mandates a set of behaviors and we must ensure that its translation σ+ mandates semantically equivalent behaviors at the target level. Based on this type translation, we demonstrate how to prove that for every target term of type σ+, there exists an equivalent source term of type σ- even when sub-terms of the target term are not necessarily "back-translatable" themselves. A key novelty of our proof, resulting in a pleasant proof structure, is that it leverages a multi-language semantics where source and target terms may interoperate.},
booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming},
pages = {431–444},
numpages = {14},
keywords = {full abstraction, multi-language semantics, back-translation, equivalence-preserving compilation, logical relations, continuation-passing style},
location = {Tokyo, Japan},
series = {ICFP '11}
}

@article{10.1145/2034574.2034830,
author = {Ahmed, Amal and Blume, Matthias},
title = {An Equivalence-Preserving CPS Translation via Multi-Language Semantics},
year = {2011},
issue_date = {September 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/2034574.2034830},
doi = {10.1145/2034574.2034830},
abstract = {Language-based security relies on the assumption that all potential attacks follow the rules of the language in question. When programs are compiled into a different language, this is true only if the translation process preserves observational equivalence.To prove that a translation preserves equivalence, one must show that if two program fragments cannot be distinguished by any source context, then their translations cannot be distinguished by any target context. Informally, target contexts must be no more powerful than source contexts, i.e., for every target context there exists a source context that "behaves the same." This seems to amount to being able to "back-translate" arbitrary target terms. However, that is simply not viable for practical compilers where the target language is lower-level and, thus, contains expressions that have no source equivalent.In this paper, we give a CPS translation from a less expressive source language (STLC) to a more expressive target language (System F) and prove that the translation preserves observational equivalence. The key to our equivalence-preserving compilation is the choice of the right type translation: a source type σ mandates a set of behaviors and we must ensure that its translation σ+ mandates semantically equivalent behaviors at the target level. Based on this type translation, we demonstrate how to prove that for every target term of type σ+, there exists an equivalent source term of type σ- even when sub-terms of the target term are not necessarily "back-translatable" themselves. A key novelty of our proof, resulting in a pleasant proof structure, is that it leverages a multi-language semantics where source and target terms may interoperate.},
journal = {SIGPLAN Not.},
month = {sep},
pages = {431–444},
numpages = {14},
keywords = {continuation-passing style, equivalence-preserving compilation, logical relations, back-translation, multi-language semantics, full abstraction}
}
@article{patterson2017linkingtyps,
  title={Linking Types for Multi-Language Software: Have Your Cake and Eat It Too},
  author={Daniel Patterson and Amal J. Ahmed},
  journal={ArXiv},
  year={2017},
  volume={abs/1711.04559}
}
@article{kennedy2006secure.net,
title = {Securing the .NET programming model},
journal = {Theoretical Computer Science},
volume = {364},
number = {3},
pages = {311-317},
year = {2006},
note = {Applied Semantics},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2006.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0304397506005536},
author = {Andrew Kennedy},
keywords = {Security, Contextual equivalence, Full abstraction, , .NET},
abstract = {The security of the .NET programming model is studied from the standpoint of fully abstract compilation of C♯. A number of failures of full abstraction are identified, and fixes described. The most serious problems have recently been fixed for version 2.0 of the .NET Common Language Runtime.}
}
@inbook{abadi1999protect,
author="Abadi, Mart{\'i}n",
editor="Vitek, Jan
and Jensen, Christian D.",
title="Protection in Programming-Language Translations",
bookTitle="Secure Internet Programming: Security Issues for Mobile and Distributed Objects",
year="1999",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="19--34",
abstract="We discuss abstractions for protection and the correctness of their implementations. Relying on the concept of full abstraction, we consider two examples: (1) the translation of Java classes to an intermediate bytecode language, and (2) in the setting of the pi calculus, the implementation of private channels in terms of cryptographic operations.",
isbn="978-3-540-48749-4",
doi="10.1007/3-540-48749-2_2",
url="https://doi.org/10.1007/3-540-48749-2_2"
}
@article{ahmed2018dagstuhl,
  author =	{Amal Ahmed and Deepak Garg and Catalin Hritcu and Frank Piessens},
  title =	{{Secure Compilation (Dagstuhl Seminar 18201)}},
  pages =	{1--30},
  journal =	{Dagstuhl Reports},
  ISSN =	{2192-5283},
  year =	{2018},
  volume =	{8},
  number =	{5},
  editor =	{Amal Ahmed and Deepak Garg and Catalin Hritcu and Frank Piessens},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{http://drops.dagstuhl.de/opus/volltexte/2018/9891},
  URN =		{urn:nbn:de:0030-drops-98911},
  doi =		{10.4230/DagRep.8.5.1},
  annote =	{Keywords: secure compilation, low-level attacks, source-level reasoning, attacker models, full abstraction, hyperproperties, enforcement mechanisms, }
}
@article{necula2005ccured,
author = {Necula, George C. and Condit, Jeremy and Harren, Matthew and McPeak, Scott and Weimer, Westley},
title = {CCured: Type-Safe Retrofitting of Legacy Software},
year = {2005},
issue_date = {May 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {3},
issn = {0164-0925},
url = {https://doi.org/10.1145/1065887.1065892},
doi = {10.1145/1065887.1065892},
abstract = {This article describes CCured, a program transformation system that adds type safety guarantees to existing C programs. CCured attempts to verify statically that memory errors cannot occur, and it inserts run-time checks where static verification is insufficient.CCured extends C's type system by separating pointer types according to their usage, and it uses a surprisingly simple type inference algorithm that is able to infer the appropriate pointer kinds for existing C programs. CCured uses physical subtyping to recognize and verify a large number of type casts at compile time. Additional type casts are verified using run-time type information. CCured uses two instrumentation schemes, one that is optimized for performance and one in which metadata is stored in a separate data structure whose shape mirrors that of the original user data. This latter scheme allows instrumented programs to invoke external functions directly on the program's data without the use of a wrapper function.We have used CCured on real-world security-critical network daemons to produce instrumented versions without memory-safety vulnerabilities, and we have found several bugs in these programs. The instrumented code is efficient enough to be used in day-to-day operations.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {may},
pages = {477–526},
numpages = {50},
keywords = {Memory safety, subtyping, pointer qualifier, libraries}
}
@inproceedings{scherer2018fabulous,
  TITLE = {{FabULous Interoperability for ML and a Linear Language}},
  AUTHOR = {Scherer, Gabriel and New, Max and Rioux, Nick and Ahmed, Amal},
  URL = {https://inria.hal.science/hal-01929158},
  BOOKTITLE = {{International Conference on Foundations of Software Science and Computation Structures (FoSSaCS)}},
  ADDRESS = {Thessaloniki, Greece},
  EDITOR = {Christel Baier and Ugo Dal Lago},
  PUBLISHER = {{Springer}},
  SERIES = {FabOpen image in new windowous Interoperability for ML and a Linear Language},
  VOLUME = {LNCS -  Lecture Notes in Computer Science},
  NUMBER = {10803},
  YEAR = {2018},
  MONTH = Apr,
  DOI = {10.1007/978-3-319-89366-2\_8},
  PDF = {https://inria.hal.science/hal-01929158/file/1707.04984.pdf},
  HAL_ID = {hal-01929158},
  HAL_VERSION = {v1},
}
@article{swasey2017robust,
author = {Swasey, David and Garg, Deepak and Dreyer, Derek},
title = {Robust and Compositional Verification of Object Capability Patterns},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {OOPSLA},
url = {https://doi.org/10.1145/3133913},
doi = {10.1145/3133913},
abstract = {In scenarios such as web programming, where code is linked together from multiple sources, object capability patterns (OCPs) provide an essential safeguard, enabling programmers to protect the private state of their objects from corruption by unknown and untrusted code. However, the benefits of OCPs in terms of program verification have never been properly formalized. In this paper, building on the recently developed Iris framework for concurrent separation logic, we develop OCPL, the first program logic for compositionally specifying and verifying OCPs in a language with closures, mutable state, and concurrency. The key idea of OCPL is to account for the interface between verified and untrusted code by adopting a well-known idea from the literature on security protocol verification, namely robust safety. Programs that export only properly wrapped values to their environment can be proven robustly safe, meaning that their untrusted environment cannot violate their internal invariants. We use OCPL to give the first general, compositional, and machine-checked specs for several commonly-used OCPs—including the dynamic sealing, membrane, and caretaker patterns—which we then use to verify robust safety for representative client code. All our results are fully mechanized in the Coq proof assistant.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {89},
numpages = {26},
keywords = {object capabilities, separation logic, robust safety, compositional verification, logical relations}
}
@article{sammler2019benefits,
author = {Sammler, Michael and Garg, Deepak and Dreyer, Derek and Litak, Tadeusz},
title = {The High-Level Benefits of Low-Level Sandboxing},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {POPL},
url = {https://doi.org/10.1145/3371100},
doi = {10.1145/3371100},
abstract = {Sandboxing is a common technique that allows low-level, untrusted components to safely interact with trusted code. However, previous work has only investigated the low-level memory isolation guarantees of sandboxing, leaving open the question of the end-to-end guarantees that sandboxing affords programmers. In this paper, we fill this gap by showing that sandboxing enables reasoning about the known concept of robust safety, i.e., safety of the trusted code even in the presence of arbitrary untrusted code. To do this, we first present an idealized operational semantics for a language that combines trusted code with untrusted code. Sandboxing is built into our semantics. Then, we prove that safety properties of the trusted code (as enforced through a rich type system) are upheld in the presence of arbitrary untrusted code, so long as all interactions with untrusted code occur at the “any” type (a type inhabited by all values). Finally, to alleviate the burden of having to interact with untrusted code at only the “any” type, we formalize and prove safe several wrappers, which automatically convert values between the “any” type and much richer types. All our results are mechanized in the Coq proof assistant.},
journal = {Proc. ACM Program. Lang.},
month = {dec},
articleno = {32},
numpages = {32},
keywords = {logical relations, type systems, language-based security, robust safety, Sandboxing, Iris}
}
@inproceedings{abate2018goodcomps,
author = {Abate, Carmine and Azevedo de Amorim, Arthur and Blanco, Roberto and Evans, Ana Nora and Fachini, Guglielmo and Hritcu, Catalin and Laurent, Th\'{e}o and Pierce, Benjamin C. and Stronati, Marco and Tolmach, Andrew},
title = {When Good Components Go Bad: Formally Secure Compilation Despite Dynamic Compromise},
year = {2018},
isbn = {9781450356930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243734.3243745},
doi = {10.1145/3243734.3243745},
abstract = {We propose a new formal criterion for evaluating secure compilation schemes for unsafe languages, expressing end-to-end security guarantees for software components that may become compromised after encountering undefined behavior---for example, by accessing an array out of bounds. Our criterion is the first to model dynamic compromise in a system of mutually distrustful components with clearly specified privileges. It articulates how each component should be protected from all the others---in particular, from components that have encountered undefined behavior and become compromised. Each component receives secure compilation guarantees---in particular, its internal invariants are protected from compromised components---up to the point when this component itself becomes compromised, after which we assume an attacker can take complete control and use this component's privileges to attack other components. More precisely, a secure compilation chain must ensure that a dynamically compromised component cannot break the safety properties of the system at the target level any more than an arbitrary attacker-controlled component (with the same interface and privileges, but without undefined behaviors) already could at the source level. To illustrate the model, we construct a secure compilation chain for a small unsafe language with buffers, procedures, and components, targeting a simple abstract machine with built-in compartmentalization. We give a careful proof (mostly machine-checked in Coq) that this compiler satisfies our secure compilation criterion. Finally, we show that the protection guarantees offered by the compartmentalized abstract machine can be achieved at the machine-code level using either software fault isolation or a tag-based reference monitor.},
booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1351–1368},
numpages = {18},
keywords = {testing, dynamic compromise, foundations, software fault isolation, mutually distrustful components, safety properties, formal definition, machine-checked proofs, undefined behavior, secure compilation, reference monitors, low-level attacks, compartmentalization},
location = {Toronto, Canada},
series = {CCS '18}
}
@InProceedings{beutner23hyperltl,
author="Beutner, Raven
and Finkbeiner, Bernd",
editor="Sankaranarayanan, Sriram
and Sharygina, Natasha",
title="AutoHyper: Explicit-State Model Checking for HyperLTL",
booktitle="Tools and Algorithms for the Construction and Analysis of Systems",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="145--163",
abstract="HyperLTL is a temporal logic that can express hyperproperties, i.e., properties that relate multiple execution traces of a system. Such properties are becoming increasingly important and naturally occur, e.g., in information-flow control, robustness, mutation testing, path planning, and causality checking. Thus far, complete model checking tools for HyperLTL have been limited to alternation-free formulas, i.e., formulas that use only universal or only existential trace quantification. Properties involving quantifier alternations could only be handled in an incomplete way, i.e., the verification might fail even though the property holds. In this paper, we present AutoHyper, an explicit-state automata-based model checker that supports full HyperLTL and is complete for properties with arbitrary quantifier alternations. We show that language inclusion checks can be integrated into HyperLTL verification, which allows AutoHyper to benefit from a range of existing inclusion-checking tools. We evaluate AutoHyper on a broad set of benchmarks drawn from different areas in the literature and compare it with existing (incomplete) methods for HyperLTL verification.",
isbn="978-3-031-30823-9"
}
@misc{patrignani2021exorcising,
  title={Exorcising Spectres with Secure Compilers}, 
  author={Marco Patrignani and Marco Guarnieri},
  year={2021},
  eprint={1910.08607},
  archivePrefix={arXiv},
  primaryClass={cs.PL}
}
@article{guarnieri2018spectector,
  author       = {Marco Guarnieri and
                  Boris K{\"{o}}pf and
                  Jos{\'{e}} F. Morales and
                  Jan Reineke and
                  Andr{\'{e}}s S{\'{a}}nchez},
  title        = {{SPECTECTOR:} Principled Detection of Speculative Information Flows},
  journal      = {CoRR},
  volume       = {abs/1812.08639},
  year         = {2018},
  url          = {http://arxiv.org/abs/1812.08639},
  eprinttype    = {arXiv},
  eprint       = {1812.08639},
  timestamp    = {Wed, 04 Jan 2023 16:50:45 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1812-08639.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
