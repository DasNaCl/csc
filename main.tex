\documentclass[a4paper,names,dvipsnames]{article}

\usepackage[T1]{fontenc}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[inference]{semantic}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{glossaries}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage[capitalize]{cleveref}
\usepackage{bm}
\usepackage{xspace}
\usepackage{etoolbox}
\usepackage{natbib}

\usepackage{tikz}
\usetikzlibrary{positioning}

\usepackage{mmmacros}
% \usepackage{./../mmmacros}

\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}

% \loadglsentries{./../acronyms}
\loadglsentries{acronyms}
\makeglossaries

\newcommand{\MK}[1]{\todo[color=orange!30]{TODO: #1}}
\newcommand{\MP}[1]{\todo[color=blue!30]{TODO: #1}}

% Definition of Ddots
\makeatletter
\def\Ddots{\mathinner{\mkern1mu\raise\p@
\vbox{\kern7\p@\hbox{.}}\mkern2mu
\raise4\p@\hbox{.}\mkern2mu\raise7\p@\hbox{.}\mkern1mu}}
\makeatother

\begin{document}

\begin{definition}[Events]\label{def:events}
  $\events$ is the set of atomic propositions hereby called events or actions.
  The internal action is $\emptyevent$.
  The action $\terminationevent$ is program termination.
\end{definition}


We assume that any programming language can be enriched with a self-composition operator in the style of \citet{barthe11}.
Furthermore, we also assume the existence of a low-equivalence relation that distinguishes program states only by their public memory.
Two traces $\trace_{1}$,$\trace_{2}$ are low-equivalent $\loweq{\trace_{1}}{\trace_{2}}$ iff all their public events coincide.

\begin{definition}[Programming Languages]\label{def:pl}
A programming language is a tuple $\left(\partials,\wellf,\singlestep,\linker\right)$ s.t.:

\begin{itemize}
  \item[$\partials$] : Set - is a set of admissible, partial programs.
  \item[$\wellf$] : $\partials$ - a judgement that holds iff a program is not partial.
  \item[$\singlestep$] : $\wholes\to\events\to\wholes$ - a step relation, where $\wholes=\{w\in\partials\ |\ \wellf w\}$.
        For $e\in\events$ and $p,p'\in\wholes$ we say for $\estep{p}{e}{p'}$ that program $p$ performs a step with action $e$ to program $p'$.
        If $e=\emptyevent$, we write $\step{p}{p'}$.
        In case $e=\terminationevent$, we write $\terminates{p}$.
  \item[$\linker$] : $\partials\to\partials\to\partials$ - links two partial programs together in some way, resulting in a new partial program.
\end{itemize}
\end{definition}
Let $\src{S},\irl{I},$ and $\trg{T}$ be any programming language.

% if we get τ1 and τ2, then there is aontehr program that does τ3 which does τ1 and τ2 in parallel
% define self-composition. and then define it with respect to low-equivalent programs
% 

% compilation of n compilers can b e reduced to compilation of two compilers

\begin{definition}[Notation for Sequences]
  For any sequence of events, let $\seqnil$ denote the empty sequence and $\seqcons{e}{\bar{t}}$ the sequence that starts with $e$ and continues with $\bar{t}$.
  Hereby, it does not matter whether $\bar{t}$ is finite or infinite, it's merely syntactic sugar to work on sequences of events.
\end{definition}

\begin{definition}[Traces]
  A trace $\trace$ is an infinite sequence of events that results from the relation $\singlestep$.
  That is, we obtain the trace $\trace=\seqcons{e_{0}}{\seqcons{e_{1}}{\dots}}$ for the execution sequence $\estep{p}{e_{0}}{\estep{p'}{e_{1}}{\dots}}$ and write $\mktrace{p}{\trace}$.
  The set of all traces is $\traces$.
\end{definition}
\noindent
We assume $\lightning$ to occur in traces representing terminating programs such that it occurs infinitely often in a one-by-one sequence.

\begin{definition}[Finite Trace Prefixes]
  A finite sequence of events $m$ is a finite trace prefix of $\trace$ iff it satisfies the following judgement.

  $$
    \inference{}{\cdot\le\trace}\hspace{2em}\inference{m\le\trace}{\seqcons{e}{m}\le \seqcons{e}{\trace}}
  $$
\end{definition}

\begin{definition}[Behavior]
  The behavior of a whole program $p$ is a set of all traces it produces, i.e. $\behav{p}=\{\trace\ |\ \mktrace{p}{\trace}\}$.
\end{definition}

\begin{definition}[Observation]
  An observation is a finite set of finite trace prefixes.
  We say that an observation $o$ is the prefix of a behavior $b$ iff $$\forall m\in o.\exists \trace\in b.m\le t$$.
\end{definition}

\begin{definition}[Properties]
  A property $\prop$ is a set of admissible traces. For a program $p$ to satisfy $\prop$ it must not produce a trace that is not part of $\prop$. Thus, $p$ satisfies $\prop$ iff $\behav{p}\subseteq\prop$ and we write $\sat{p}{\prop}$.
\end{definition}

\begin{definition}[Hyperproperties]
  A hyperproperty $H$ is a set of admissible sets of traces. Thus, if $p$ satisfies $H$ (also written $\sat{p}{H}$), then $\behav{p}\in H$.
\end{definition}

\begin{lemma}[Lifting Properties]
  Given a property $\pi$, there exists a unique hyperproperty $\lift{\pi}$ that satisfies the exact same policy.
\end{lemma}
\begin{proof}
  We want $\forall p \in\partials, \sat{p}{\prop}\equiv\sat{p}{\lift{\prop}}$.
  Henceforth, given a $p\in\partials$, we have $\behav{p}\subseteq\prop$ iff $\behav{p}\in\lift{\prop}$.
  Note that if $\behav{p}\subseteq\prop$, we have $\behav{p}\in\left\{\Pi\ |\ \Pi=\behav{p}\subseteq\prop\right\}$.
  Thus, $\lift{\prop}$ is the set of all possible program behaviors that are a subset of $\prop$.
  This is exactly the powerset of $\prop$ and we conclude $\lift{\prop}=\powerset{\prop}$.
\end{proof}
\noindent
The lifting of properties to a singleton set does not suffice, since the empty behavior trivially satisfies any property $\emptyset\subseteq\prop=\{\trace\}$, but if we would define $\lift{\trace}=\{\{\trace\}\}$, then $\emptyset\not\in\lift{\trace}$.

\begin{lemma}[Property Satisfaction Refinement]
  For a property $\prop$ that refines $\prop'$, i.e. $\prop\subseteq\prop'$, if any $p\in\partials$ satisfies $\sat{p}{\prop'}$, then $\sat{p}{\prop}$.
\end{lemma}
\begin{proof}
  Pick any property $\prop'$ and $p\in\partials$ such that $\sat{p}{\prop}$ and assume $\prop\subseteq\prop'$.
  Simple unfolding reveals $\behav{p}\subseteq\prop\implies\behav{p}\subseteq\prop'$.
\end{proof}
\noindent
For lifted properties, this refinement property also holds on the hyperproperty level.
However, it does not work for any hyperproperty~\cite{clarkson08}.

\begin{definition}[Robust Property Satisfaction]
  A program $p$ robustly satisfies a property $\prop$, written $\rsat{p}{\prop}$, iff $\forall C\in\partials,\sat{C\linker p}{\prop}$. The same notation is used for robust hyperproperty satisfaction.
\end{definition}

\begin{lemma}[Weakening Robust Satisfaction]\label{lem:weaken-rsat}
  Given classes $\cC_{1}, \cC_{2}$ and any program $p$ such that
  \begin{assumptions}
    \item\label{lem:weaken-rsat:ass:a} $\cC_{1}\subseteq\cC_{2}$
    \item\label{lem:weaken-rsat:ass:b} $\rsat{p}{\cC_{2}}$
  \end{assumptions}
  We show
  \begin{goals}
    \item\label{lem:weaken-rsat:goal:i} $\rsat{p}{\cC_{1}}$
  \end{goals}
\end{lemma}
\begin{proof}
  Unfolding \Cref{lem:weaken-rsat:goal:i}, let $\Pi\in\cC_{2}$ and $p$ be a program, we want to show that $\rsat{p}{\Pi}$.
  By \Cref{lem:weaken-rsat:ass:a}, we also know that $\Pi\in\cC_{1}$.
  Thus, we can use \Cref{lem:weaken-rsat:ass:b} to conclude.
\end{proof}

\begin{definition}[Classes]
  A class of hyperproperties $\cC$ is a set of hyperproperties.
  Likewise, a class of properties $\cC$ is a set of hyperproperties, where every property is lifted to the hyperproperty level.
  From now on, we use $\Pi$ for elements of any class $\cC$ in case it does not matter whether it is a lifted property or any hyperproperty.
\end{definition}

\begin{definition}[Compilers]
  A compiler between languages $\S$ and $\T$ is a partial function $\stcomp{\bullet}$ from $\src{\partials}$ to $\trg{\partials}$.
\end{definition}

\begin{definition}[Robust Trace-Hyperproperty Preservation]\label{def:rtp}
  For a given class $\cC$, a compiler from languages $\S$ to $\T$ robustly preserves $\cC$ iff
  $$
  \forall\Pi\in\cC,\forall\src{p}\in\src{\partials},\rsat{\src{p}}{\Pi}\implies\rsat{\stcomp{\src{p}}}{\Pi}
  $$
  We write $\rtp{\stcomp{\bullet}}{\cC}$.
  In case we write $\rtp{\stcomp{\bullet}}{\collapse{\cC}}$, substitute the $\cC$ in above definition with $\left\{ \collapse{\cC} \right\}$.
\end{definition}

\begin{definition}[Sequential Composition of Compilers]
  Given two compilers $\sicomp{\bullet}$ and $\itcomp{\bullet}$, their sequential composition is $\sitcomp{\bullet}=\itcompN{\sicomp{\bullet}}$.
\end{definition}
% we can propagate through the assumptions from src langs to intermediate langs
%

\begin{lemma}[Weakening RTP]\label{lem:weaken}
  Given classes $\cC_{1}, \cC_{2}$ such that
  \begin{assumptions}
    \item $\cC_{1}\subseteq\cC_{2}$
    \item $\rtp{\stcomp{\bullet}}{\cC_{2}}$
  \end{assumptions}
  We show
  \begin{goals}
    \item $\rtp{\stcomp{\bullet}}{\cC_{1}}$
  \end{goals}
\end{lemma}
\begin{proof}
  Using \Cref{def:rtp} on the goal, let $\Pi\in\cC_{1}$ and $\src{p}\in\src{\partials}$ such that $\rsat{\src{p}}{\Pi}$, so what's left to prove is $\rsat{\stcomp{p}}{\Pi}$.
  Since $\cC_{1}\subseteq\cC_{2}$ and $\Pi\in\cC_{1}$, we know that $\Pi\in\cC_{2}$.
  Thus, we can apply the assumption $\rtp{\stcomp{\bullet}}{\cC_{2}}$ to our goal, leaving us with $\rsat{\src{p}}{\Pi}$ to show, which was an assumption we made.
\end{proof}

\begin{definition}[Safety Properties]
  The class of safety properties contains the lifting of all properties that can be refuted with a finite trace prefix:
  $$
  \cSafety = \left\{\lift{\prop}\ |\ \forall \trace\in\traces, t\not\in\lift{\prop} \text{ iff } \exists m\ge\trace,\forall \trace'\in\traces,m\le\trace'\implies\trace'\not\in\lift{\prop}\right\}
  $$
\end{definition}

\begin{definition}[Hypersafety Properties]\label{def:hsafety}
  The class of hypersafety properties contains all hyperpropert that can be refuted with an observation:
  $$
  \cHSafety = \left\{\Pi\ |\ \forall b\in 2^{\traces},b\not\in\Pi\text{ iff  }\exists o\ge b,\forall b'\in 2^{\traces},o\le b'\implies b'\not\in\Pi\right\}
  $$
\end{definition}

\begin{lemma}[Safety is entailed in Hypersafety]
  $\cSafety\subseteq\cHSafety$.
\end{lemma}

\begin{definition}[Subset Closed Hyperproperties]
  The class of hyperproperties that are closed with respect to the subset relation is
  $$
  \cSS = \left\{H\ |\ \forall X\in H, \forall Y\subseteq X, Y \in H\right\}
  $$
\end{definition}

\begin{lemma}[Hypersafety is entailed in SSC]
  $\cHSafety\subseteq\cSS$.
\end{lemma}

\begin{definition}[K-Hypersafety]
  Exactly the same as \Cref{def:hsafety}, but the observations $o$ are restricted to cardinality $k$.
  2-Hypersafety is simply $k=2$. \Cref{def:ni} gives an example instance of a classic 2-hypersafe property.
\end{definition}

\begin{definition}[Nontermination]
  Nontermination is a safety property: Any finite trace prefix with $\terminationevent$ violates this property.
\end{definition}

\begin{definition}[Mutual Exclusion]
  Mutual Exclusion (MutEx) means that no two processes during a program execution enter the same critical section.
\end{definition}

\begin{definition}[Determinism]
  Determinism is a 2-hypersafety property, since any two program executions with the same input must yield the same output.
\end{definition}

\begin{definition}[Non-Interference ($\Ni$)]\label{def:ni}
  We define the class containing the non-interference hyperproperty as:
  $$
  \Ni = \left\{ H | \forall \trace_{1},\trace_{2}\in H. \loweq{\trace_{1}}{\trace_{2}}\implies\trace_{1}=\trace_{2} \right\}
  $$
\end{definition}
Note that $=$ may not be strict equality, but some suitable trace equivalence that checks both public and private actions, instead of just public.

\begin{definition}[Average Response Time (ART)]
  The average response time over all executions less than some arbitrary constant~\cite{clarkson08} is a practically useful hyperproperty that is not subset closed.
\end{definition}
Consider the behavior $\{\trace_{1},\trace_{2},\trace_{3}\}$ where $\trace_{1},\trace_{2}$ each take 1 second and $\trace_{3}$ 4 seconds to run.
If the chosen constant is 2, the hyperproperty would be fulfilled. However, the subset behavior $\{\trace_{3}\}$ has an average time of 4, double the bound set by the property.

\begin{lemma}[Classes Lattice]
  Classes with $\subseteq$ form a lattice.
\end{lemma}
\begin{proof}
  The class with all hyperproperties is the top element $\top=\powerset{\traces}$, while the class with no hyperproperties whatsoever is $\bot=\{\}$.
  Obviously, a partial order due to set inclusion.
  $\cap$ is least upper and $\cup$ greatest lower bound of any given pair of subsets of a given class.
\end{proof}

\begin{figure}[h]
  \centering
  \begin{tikzpicture}[node distance=4mm,every node/.style={align=center}]
    \node (top) {$\top$};
    \node[below = of top.south] (SSC) {$\cSS$};
    \node[below = of SSC.south] (HSafe) {$\cHSafety$};
    \node[below = of HSafe.south] (HKSafe) {$\cKHSafety$};
    \node[below = of HKSafe.south] (H2Safe) {$\cTwoHSafety$};
    \node[below = of H2Safe.south] (Safe) {$\cSafety$};

    % Specialized classes
    \node[below right = of Safe.south] (Mutex) {$\mutex$};
    \node[below left = of Safe.south,xshift = 0.75em] (NonTerm) {$\nonterm$};

    \node[below left = of H2Safe.south west] (Determ) {$\determ$};
    \node[below right = of H2Safe.south east] (NI) {$\Ni$};

    \node[below = of Safe.south] (emptyspace) {};
    \node[below = of emptyspace.south] (Bot) {$\bot$};

    % edges
    \draw[-] (top.south) -- (SSC.north);
    \draw[-] (SSC.south) -- (HSafe.north);
    \draw[-] (HSafe.south) -- (HKSafe.north);
    \draw[-] (HKSafe.south) -- (H2Safe.north);
    \draw[-] (H2Safe.south) -- (Safe.north);
    \draw[-] (H2Safe.south) -- (Determ.north);
    \draw[-] (H2Safe.south) -- (NI.north);
    \draw[-] (Safe.south) -- (Mutex.north);
    \draw[-] (Safe.south) -- (NonTerm.north);
    \draw[-] (Determ.south) |- (Bot.west);
    \draw[-] (NI.south) |- (Bot.east);
    \draw[-] (Mutex.south) -- (Bot.north);
    \draw[-] (NonTerm.south) -- (Bot.north);
  \end{tikzpicture}
  \caption{Sketch of a fraction of the infinitely sized lattice of classes. The diagram should be read from top to bottom. A connecting edge between two nodes means that the bottom one is a subset of the top one.}
\end{figure}

\begin{lemma}[Sequential Composition with RTP]\label{lem:seqcompo}
  Given $\rtp{\sicomp{\bullet}}{\cC_{1}}$ and $\rtp{\itcomp{\bullet}}{\cC_{2}}$, then $\rtp{\sitcomp{\bullet}}{\cC_{1}\cap\cC_{2}}$.
\end{lemma}
\begin{proof}
  We need to show $\rtp{\sitcomp{\bullet}}{\cC_{1}\cap\cC_{2}}$.
  By definition, assume $\Pi\in\cC_{1}\cap\cC_{2}$ and $\src{p}\in\src{\partials}$ such that $\rsat{\src{p}}{\Pi}$.
  What is left to show is $\rsat{\sitcomp{\src{p}}}{\prop}$.
  Note that $\Pi\in\cC_{2}$ and that $\sicomp{\src{p}}\in\irl{\partials}$, allowing us to apply $\rtp{\itcomp{\bullet}}{\cC_{2}}$ changing our goal to $\rsat{\sicomp{\src{p}}}{\Pi}$.
  Since $\Pi\in\cC_{1}$ also holds, we can this time apply $\rtp{\stcomp{\bullet}}{\cC_{1}}$.
  What is left to show is $\rsat{\src{p}}{\Pi}$, which is an assumption of ours.
\end{proof}

\begin{definition}[Upper Composition]
  Given two compilers $\stcomp{\bullet}$ and $\itcomp{\bullet}$, their upper composition is

  $$\uhcsitcomp{\bullet}=\lambda p.\begin{cases}\stcomp{p} &\text{if }p\in\src{\partials}\\
                                                \itcomp{p} &\text{if }p\in\irl{\partials}\end{cases}$$.
\end{definition}

\begin{lemma}[Upper Composition with RTP]
  Given $\rtp{\stcomp{\bullet}}{\cC_{1}}$ and $\rtp{\itcomp{\bullet}}{\cC_{2}}$, then $\rtp{\uhcsitcomp{\bullet}}{\cC_{1}\cap\cC_{2}}$.
\end{lemma}
\begin{proof}
  Analogous argument as in \Cref{lem:seqcompo}, but with a case distinction on whether the source program is element of $\S$ or $\I$.
\end{proof}

\begin{definition}[Lower Composition]
  Given two compilers $\stcomp{\bullet}$ and $\sicomp{\bullet}$, their lower composition is $\lhcsitcomp{\bullet}$.
\end{definition}

\begin{lemma}[Lower Composition with RTP]
  Given $\rtp{\stcomp{\bullet}}{\cC_{1}}$ and $\rtp{\sicomp{\bullet}}{\cC_{2}}$, then $\rtp{\lhcsitcomp{\bullet}}{\cC_{1}\cap\cC_{2}}$.
\end{lemma}
\begin{proof}
  Analogous argument as in \Cref{lem:seqcompo}, but with a case distinction on whether the compiled source program is element of $\I$ or $\T$.
\end{proof}

% spectre : compile one part to v4, the other to v5

% are we always just preserving the lub? can we preserve something stronger?
% => goal is to make target class in composed compiler stronger

% hypersafety implies safety    prove safety preservation, implies hypersafety (for some reasonable constraints)
%

% going a level deeper: what can we say about individual properties? composing individual props
% e.g. prop for spec safety and memsafety, how does their conjunction work out?
%
% speculative safety encompasses hypersafety

% constant time : assumes memsafety, then somethings, thus crypto const time
%
%

\begin{lemma}[Diamond]\label{lem:diamond}
  Given $\rtp{\lhcsiocomp{\bullet}}{\cC_{1}}$ and $\rtp{\uhciotcomp{\bullet}}{\cC_{2}}$ with $\stcomp{\bullet} = \lambda\src{p}.\uhciotcomp{\lhcsiocomp{p}}$, then $\rtp{\stcomp{\bullet}}{\cC_{1}\cap\cC_{2}}$.
\end{lemma}
\begin{proof}
  Straightforward using \Cref{lem:seqcompo}.
\end{proof}

\begin{lemma}[Swappable]\label{lem:swappable}
  Given $\rtp{\ttcomp{\bullet}_{(1)}}{\cC_{1}}$ and $\rtp{\ttcomp{\bullet}_{(2)}}{\cC_{2}}$, then $\rtp{\ttcompN{\ttcomp{\bullet}_{(2)}}_{(1)}}{\cC_{1}\cap\cC_{2}}$ and $\rtp{\ttcompN{\ttcomp{\bullet}_{(1)}}_{(2)}}{\cC_{1}\cap\cC_{2}}$.
\end{lemma}
\begin{proof}
  Both follow from \Cref{lem:seqcompo}.
\end{proof}

\begin{lemma}[Mingle]
  Given
  \begin{assumptions}
  \item\label[ass]{lem:sandwich:ass:a} $\forall\Pi\in\cC_{2}.\forall\src{p}\in\src{\partials}.\rsat{\src{p}}{\Pi}\implies \Pi\in\cC_{1}$
  \item\label[ass]{lem:sandwich:ass:b} $\forall\Pi\in\cC_{1}.\forall\trg{p}\in\trg{\partials}.\rsat{\trg{p}}{\Pi}\implies \Pi\in\cC_{2}$ (not needed)
  \item\label[ass]{lem:sandwich:ass:c} $\rtp{\stcomp{\bullet}}{\cC_{1}}$
  \end{assumptions}
  we have
  \begin{goals}
  \item\label[goal]{lem:sandwich:goal:i} $\rtp{\stcomp{\bullet}}{\cC_{2}}$
  \end{goals}
\end{lemma}
\begin{proof}
  Unfolding \Cref{lem:sandwich:goal:i}; Let $\Pi\in\cC_{2}$ and $\src{p}\in\src{\partials}$ such that $\rsat{\src{p}}{\Pi}$, leaving us with $\rsat{\stcomp{\src{p}}}{\Pi}$ to prove.

  Apply \Cref{lem:sandwich:ass:c}, giving us as new goals $\Pi\in\cC_{1}$ and $\rsat{\src{p}}{\Pi}$, the latter following easily by the exact same assumption made before.

  However, we still need to argue that $\Pi\in\cC_{1}$.

  Instatiate the universal quantifications in \Cref{lem:sandwich:ass:a} with $\Pi$ and $\src{p}$. Apply that to our goal.
  What is left to show is $\rsat{\src{p}}{\Pi}$, which we've proven before already.
\end{proof}

\begin{lemma}[RSP may imply k-RSHP]
  Given
  \begin{assumptions}
  \item\label[ass]{lem:rspimplkrshp:ass:a} $\S$ and $\T$ have $\loweq{}{}$ and $\selfcompo{}{}$ operators
  \item\label[ass]{lem:rspimplkrshp:ass:b} $\Pi\in\cSafety$
  \item\label[ass]{lem:rspimplkrshp:ass:c} $\src{p}\in\src{\partials}$ with $\rsat{\src{p}}{\Pi}$
  \item\label[ass]{lem:rspimplkrshp:ass:d} $\rtp{\stcomp{\bullet}}{\cSafety}$
  \end{assumptions}
  Then
  \begin{goals}
  \item\label[goal]{lem:rspimplkrshp:goal:i} $\exists\stcomp{\bullet}.\sat{\stcomp{\src{p}}}{\text{k-RSHP}}$
  \end{goals}
\end{lemma}
\begin{proof}
  (intuition)

  Take $\src{p}\in\src{\partials}$ and construct the k-product program according to \citet{barthe11}.
  Feed the input into the compiler from \Cref{lem:rspimplkrshp:ass:d}.
  Instantiate the existential in \Cref{lem:rspimplkrshp:goal:i} with the modified compiler.
  Since the product program reflects the behavior of $\src{p}$, the transformation does not interfere with robust property satisfaction.
  Furthermore, \Cref{lem:rspimplkrshp:ass:d} guarantees us that the compiled k-product program of $\src{p}$ is safe.
  Since the k-product construction soundly embeds $k-RSHP$ properties into $\cSafety$, the claim follows.
\end{proof}


\begin{definition}[Instrumentation]\label{def:instrumentation}
  A source code instrumentation done by a compiler takes a program in language $\T$ and emits an altered version of the same program in $\T$ such that it does not go wrong for some class of security relevant (hyper-)properties.
  Formally, given a $\cC$ the instrumentation done by $\ttcomp{\bullet}$ ensures:

  $$
  \forall \trg{p}\in\trg{\partials}, \rsat{\ttcomp{p}}{\cC}
  $$

  We write $\instr{\ttcomp{\bullet}}{\cC}$.
\end{definition}
% S -> I and I -> T
% I -> T preserves memory safety


% enrich pipeline from source to target to see how to do the preservation from source in intermediate/target lang

\begin{definition}[Secure Instrumentation with Respect to $\cC$]\label{def:secure-instrumentation}
  A secure instrumentation with respect to some class $\cC$ ensures (hyper-)properties described by some class $\cC'$ without violating $\cC$-satisfying programs. We write $\sinstr{\ttcomp{\bullet}}{\cC}{\cC'}$.
  Thus, in addition to the condition presented in \Cref{def:instrumentation}, we require:

  $$
  \forall\Pi\in\cC.\forall \trg{p}\in\trg{\partials}, \rsat{\trg{p}}{\Pi} \implies \rsat{\ttcomp{p}}{\Pi} \wedge \Pi\in\cC\cap\cC'
  $$

\end{definition}

\begin{definition}[No-v* Classes]
  Let $\nvOne$ denote the singleton-class such that no SPECTRE v1 attack can happen.
  Analgously, define $\nvFour$ as a singleton-class that disallows SPECTRE v4 attacks and $\nvOneFour$ as the class that disallows both v1 and v4 attacks, i.e. $\nvOneFour=\nvOne\cap\nvFour$.
\end{definition}

\begin{example}
  Consider a compiler $\ttcomp{\bullet}_{1}$ such that $\sinstr{\ttcomp{\bullet}_{1}}{\nvOne}{\nvFour}$ and, similarily,
  $\ttcomp{\bullet}_{4}$ such that $\sinstr{\ttcomp{\bullet}_{4}}{\nvFour}{\nvOne}$.

  \begin{lemma}\label{lem:vOnevFourSafe}
    Using above compilers, we now show that $\rtp{\ttcompN{\ttcomp{\bullet}_{1}}_{4}}{\nvOneFour}$.
  \end{lemma}
  \begin{proof}
    By \Cref{lem:seqcompo} we get two goals, $\rtp{\ttcomp{\bullet}_{1}}{\nvOneFour}$ and $\rtp{\ttcomp{\bullet}_{4}}{\nvOneFour}$.

    Since both cases are symmetrical, we only consider $\rtp{\ttcomp{\bullet}_{1}}{\nvOneFour}$ now.

    Unfolding the definition of the goal, suppose there is a $\Pi\in\nvOneFour$ and $\trg{p}\in\trg{\partials}$ such that $\rsat{\trg{p}}{\Pi}$, while our new goal is $\rsat{\ttcomp{p}_{1}}{\Pi}$.

    Strengthen the goal so that we need to show $\rsat{\ttcomp{p}_{1}}{\Pi}\wedge\Pi\in\nvOneFour$. Now, apply \Cref{def:secure-instrumentation}, so the only things left to show are $\Pi\in\nvOne$ and $\rsat{\trg{p}}{\Pi}$.
    Both follow easily from our assumptions.
  \end{proof}
  \begin{lemma}
    $\rtp{\ttcompN{\ttcomp{\bullet}_{4}}_{1}}{\nvOneFour}$
  \end{lemma}
  \begin{proof}
    By \Cref{lem:vOnevFourSafe} and \Cref{lem:swappable}.
  \end{proof}

  We now consider what happens if one of the two instrumentations is not secure with respect to the respective other class.
  However, we focus on the case where the v1-instrumentation is insecure with respect to v4, due to symmetry.

  \begin{lemma}
    $\rtp{\ttcompN{\ttcomp{\bullet}_{1}}_{4}}{\nvOneFour}$
  \end{lemma}
  \begin{proof}
    Note that $\ttcomp{p}_{1}$ is a secure $\T$ program with respect to SPECTRE v1 attacks, given any $\trg{p}\in\trg{\partials}$.

    Unfolding, let $\Pi\in\nvOneFour$ and $\trg{p}\in\trg{\partials}$ such that $\rsat{\trg{p}}{\Pi}$, our goal changes to $\rsat{\ttcompN{\ttcomp{\trg{p}}_{1}}_{4}}{\Pi}$.

    Strengthen what we want to prove to $\rsat{\ttcompN{\ttcomp{\trg{p}}_{1}}_{4}}{\Pi}\wedge\Pi\in\nvOneFour$.
    Apply \Cref{def:secure-instrumentation}, giving us proof-obligations that are already part of our assumptions.
  \end{proof}

  \begin{lemma}
    $\rtp{\ttcompN{\ttcomp{\bullet}_{4}}_{1}}{\nvOne}$
  \end{lemma}
  \begin{proof}
    Let $\trg{p}=\ttcomp{p'}_{4}$ be some program that is the result of plugging $\trg{p'}\in\trg{\partials}$ into $\ttcomp{\bullet}_{4}$.

    Our goal becomes $\rtp{\ttcomp{p}_{1}}{\nvOne}$. Unfolding it, let $\Pi\in\nvOne$ and $\trg{p}\in\trg{\partials}$ such that $\rsat{\trg{p}}{\Pi}$, where what is left to prove is $\rsat{\ttcomp{p}_{1}}{\nvOne}$.

    The goal follows immediately by \Cref{def:instrumentation}, since $\ttcomp{p}_{1}$ is an instrumentation for $\nvOne$.
  \end{proof}

  Finally, if both are insecure instrumentations, the strongest result one can get is either the robust preservation of $\nvOne$ or $\nvFour$, depending on which compiler is run last.
\end{example}

We have seen that we can already swap robust compilers with same input and output language in a compilation pipeline.
Now, we want to formalize this idea of ``being able to swap things around'' for source code instrumentations.

\begin{definition}[Swappable Instrumentations]
  We define vertical compositionality as follows.
  Let $\bar{\cC}$ be a set of classes that are eventually used in the compilation pipeline.
  Given a class $\cC\in\bar{\cC}$ the particular instrumentation $\ttcomp{\bullet}$ ensures any program to robustly satisfy, we can swap the instrumentation in the pipeline \textit{freely} around iff:

  $$
  \forall\cC'\in\bar{\cC}. \sinstr{\ttcomp{\bullet}}{\cC}{\cC'}
  $$
\end{definition}
\MK{it'd be nice to have a property-free version of this, since this here is TEDIOUS to prove in real-world}

\clearpage
Experimental
\begin{definition}[Encoders]
  An encoder $\tenc{\src{\bullet}}$ from language $\S$ to $\T$ is a function that constructs an abstract representation of the given $\S$ program as a $\T$ program.
\end{definition}
\noindent
Think of encoders as parsers.

\begin{definition}[Interpreters]
  An interpreter $\stinterp$ is a $\T$ program that faithfully implements the semantics of $\S$.
  That is, given $\src{p}\in\src{\partials}$ and some encoding function $\tenc{\src{\bullet}}$, then $\mktrace{\stinterp \trg{\linker} \tenc{\src{p}}}{\tau} \Leftrightarrow \mktrace{\src{p}}{\tau}$.
\end{definition}
Note: For an interpreter to \textit{faithfully} realize the semantics of $\S$, we really need the equivalence.
Say we only consider the $\Leftarrow$ direction as defining characteristic, then an interpreter that e.g. tosses a coin and thus $\behav{\stinterp\trg{\linker}\tenc{\src{p}}}=\{\trace_{1},\trace_{2}\}$ given $\behav{\src{p}}=\{\trace_{1}\}$ would be acceptable.
However, an interpreter that 99\% of the time emits $\trace_{2}$ is certainly not what we want.
Consider the converse, so $\Rightarrow$ as defining characteristic.
Then, swapping the behaviors from the previous example, the interpreter does not \textit{faithfully} simulate non-determinism that is present in the source language.
% Due to this, interpreters in our world always robustly satisfy relational hyperproperties

\begin{definition}[Specializers]
  A specializer $\ttspec{\bullet}$ is a $\T$ program that, given an encoding of another $\T$ program as input, emits a specialized version of that $\T$ program.
  So, given a partial program $\trg{p}$ and some set of inputs $\trg{x}\in\trg{\partials}$, $\ttspec{\tenc{p \linker x}}$ always terminates with a residual program $\trg{p'}$ such that $\behav{\trg{p\linker x}}=\behav{\trg{p'}}$.
\end{definition}
\noindent

\begin{definition}[2nd Futamura Projection]
  Given a specializer $\ttspec{\bullet}$, an interpreter $\stinterp$, and an encoding $\tenc{\src{\bullet}}$, we can compose them to a compiler $\stcomp{\bullet} = \ttspec{\stinterp \tenc{\src{\bullet}}}$.~\cite{Futamura1999}
\end{definition}

\clearpage


\myfig{
	\vspace{-1em}
  \begin{gather*}
  \begin{aligned}
  \mi{Expressions}~\src{e} \bnfdef& \text{side-effect free operation leading a value in }\src{\nat}\\
  %
  \mi{Commands}~\src{c} \bnfdef&\ \src{skip} \mid \src{c_{1};c_{2}} \mid \src{let\ v := e} \mid \src{while\ e \{c\}} \mid \src{let\ x := new\ e} \mid \\
                               &\ \src{delete\ x} \mid \src{let\ v := x[e]} \mid \src{x[e_{1}] := e_{2}}\\
  %
  \mi{Types}~\taus \bnfdef&\ \src{\nat} \mid \src{\arr} \hspace{0.5cm}
  %
  \mi{Values}~\src{v} \bnfdef\ \src{\widehat{n}}\in\nat \mid \src{\bar{n}}\in\nat^{\nat}\\
  %
  \mi{Contexts}~\src{C} \bnfdef&\ \src{c_{1};\hole{\cdot};c_{2}} \hspace{0.5cm}
  \mi{Programs}~\src{p} \bnfdef\ \src{P\ c} \\
  %
  \mi{Typing. Env.}~\src{\Gamma} \bnfdef&\ \src{\hole{\cdot}} \mid \Gammas,\src{x:\tau} \hspace{0.5cm}
  \mi{Eval. Env.}~\src{\Delta} \bnfdef\ \src{\hole{\cdot}} \mid \Deltas,\src{x\mapsto v}\\
  %
  \mi{Heaps}~\src{H} \bnfdef&\ \src{\hole{\cdot}} \mid \src{v}::\src{H} \hspace{0.5cm}
  \mi{Location\ Mappings}~\src{A}\bnfdef\ \src{\hole{\cdot}} \mid \src{A,x\mapsto \widehat{l}} \\
  \end{aligned}
  \end{gather*}
}{while-syntax}{Syntax of $\whileA$}


\myfig{
  \judgbox{\typechecks{\Gamma_1}{c}{\Gamma_2}}{,,Under context $\src{\Gamma_{1}}$, the command $\src{c}$ is ok and produces context $\src{\Gamma_{2}}$.''}

  \begin{center}
  \typerule{$t-\src{skip}$}{
	}{
  \typechecks{\Gamma}{skip}{\Gamma}
	}{w-t-skip}
  %
  \typerule{$t-\src{Seq}$}{
    \typechecks{\Gamma_1}{p_1}{\Gamma_2}&
    \typechecks{\Gamma_2}{p_2}{\Gamma_3}
	}{
  \typechecks{\Gamma_1}{p_1;p_2}{\Gamma_3}
	}{w-t-seq}
  %
  \typerule{$t-\src{ExprAssign}$}{
    \forall\src{\tau},\src{v:\tau}\not\in\src{\Gamma}
	}{
  \typechecks{\Gamma}{let\ v := e}{\Gamma,v:\nat}
	}{w-t-exprassign}
  %
  \typerule{$t-\src{Loop}$}{
  \typechecks{\Gamma}{c}{\Gamma}
	}{
  \typechecks{\Gamma}{while\ e\ \{c\}}{\Gamma}
	}{w-t-loop}
  %
  \typerule{$t-\src{new}$}{
	}{
  \typechecks{\Gamma}{let\ v := new\ e}{\Gamma,v:\arr}
	}{w-t-new}
  %
  \typerule{$t-\src{delete}$}{
	}{
  \typechecks{\Gamma,v:\arr}{delete\ v}{\Gamma}
	}{w-t-delete}
  %
  \typerule{$t-\src{read}$}{
	}{
  \typechecks{\Gamma,x:\arr}{let\ v := x[e]}{\Gamma,x:\arr,v:\nat}
	}{w-t-read}
  %
  \typerule{$t-\src{write}$}{
	}{
  \typechecks{\Gamma,x:\arr}{x[e_1] := e_2}{\Gamma,x:\arr}
	}{w-t-write}
  \end{center}
}{w-command-ty}{Checking of $\whileA$ commands.}

\myfig{
  \judgbox{\typechecks{}{p}{\Gamma}}{,,The program $\src{p}$ is ok and produces context $\src{\Gamma}$.''}

  \begin{center}
  \typerule{$t-\src{prog}$}{
    \typechecks{\hole{\cdot}}{c}{\Gamma} &
    \forall \src{x},\src{x:\arr}\not\in\src{\Gamma}
	}{
  \typechecks{\hole{\cdot}}{P\ c}{\Gamma}
	}{w-t-prog}
  \end{center}
}{w-program-ty}{Checking of $\whileA$ programs.}

We assume the existence of an expression evaluator $\exprevals{e}{\Delta}{v}$, which evaluates $\src{e}$ under evaluation environment $\Deltas$ to value $\src{v}$.

Furthermore, variables uniquely occur in $\Gammas$ and $\Deltas$ and are unguessable.


\myfig{
  \begin{gather*}
  \begin{aligned}
  \mi{Events}~\src{e} \bnfdef& \src{Internal} \mid \src{Alloc\ x\ \widehat{n}} \mid \src{Dealloc\ x} \mid \src{Read\ x\ \widehat{n}} \mid \src{Write\ x\ \widehat{n}\ \widehat{m}}
  \end{aligned}
  \end{gather*}
}{w-events}{Events of $\whileA$.}

\myfig{
  \judgbox{\evals{H_0}{A_0}{\Delta_0}{p_0}{e}{p_1}{H_1}{A_1}{\Delta_1}}{%
    ,,Under heap $\src{H_{0}}$, array location map $\src{A_{0}}$, \\
    and evaluation environment $\src{\Delta_{0}}$ the program $\src{p_{0}}$ is\\%
    evaluated to $\src{p_{1}}$ emitting an event $\src{e}$ and a resulting\\%
    heap $\src{H_{1}}$, array location map $\src{A_{1}}$, and \\
    an evaluation context $\src{\Delta_{1}}$.''}
  %
  \typerule{$e-skip$}{
  }{
    \evals{H}{A}{\Delta}{skip}{}{skip}{H}{A}{\Delta}
  }{w-e-skip}
  %
  \typerule{$e-lseq$}{
    \evals{H}{A}{\Delta}{p_0}{e}{p_0'}{H'}{A'}{\Delta'}
  }{
    \evals{H}{A}{\Delta}{p_0;p_1}{e}{p_0';p_1}{H'}{A'}{\Delta'}
  }{w-e-lseq}
  %
  \typerule{$e-rseq$}{
  }{
    \evals{H}{A}{\Delta}{skip;p_1}{}{p_1}{H}{A}{\Delta}
  }{w-e-rseq}
  %
  \typerule{$e-assign$}{
    \forall\src{v},\src{x\mapsto v}\not\in\Deltas&
    \exprevals{e}{\Delta}{v}
  }{
    \evals{H}{A}{\Delta}{let\ x := e}{}{skip}{H}{A}{\Delta,x\mapsto v}
  }{w-e-assign}
  %
  \typerule{$e-loopcont$}{
    \exprevals{e}{\Delta}{v} & v \not = \src{\widehat{0}}
  }{
    \evals{H}{A}{\Delta}{while\ e\ \{c\}}{}{c;while\ e\ \{c\}}{H}{A}{\Delta}
  }{w-e-loopcont}
  %
  \typerule{$e-loopstop$}{
    \exprevals{e}{\Delta}{v} & v = \src{\widehat{0}}
  }{
    \evals{H}{A}{\Delta}{while\ e\ \{c\}}{}{skip}{H}{A}{\Delta}
  }{w-e-loopstop}
  %
  \\
  \typerule{$e-new$}{
    \exprevals{e}{\Delta}{\widehat{n}} &
    \src{H'} = grow\ \src{H}\ \widehat{n}
  }{
    \evals{H}{A}{\Delta}{let\ x:= new\ e}{Alloc\ x\ \widehat{n}}{skip}{H'}{A,x\mapsto|H|}{\Delta}
  }{w-e-new}
  %
  \typerule{$e-delete$}{
  }{
    \evals{H}{A,x\mapsto\widehat{l}}{\Delta}{delete\ x}{Dealloc\ x}{skip}{H}{A}{\Delta}
  }{w-e-delete}
  %
  \\
  \typerule{$e-get$}{
    \exprevals{e}{\Delta}{\src{\widehat{n}}} &
    lookup\ \src{H}\ \widehat{l + n} = Some\ \widehat{v}
  }{
    \evals{H}{A,x\mapsto\widehat{l}}{\Delta}{let\ y := x[e]}{Read\ x\ \widehat{n}}{skip}{H}{A,x\mapsto\widehat{l}}{\Delta,y\mapsto\widehat{v}}
  }{w-e-get}
  %
  \\
  \typerule{$e-set$}{
    \exprevals{e_1}{\Delta}{\widehat{n}} &
    \exprevals{e_2}{\Delta}{\widehat{m}} &
    \src{H'} = replace\ \src{H}\ \widehat{l + n}\ \src{\widehat{m}}
  }{
    \evals{H}{A,x\mapsto\widehat{l}}{\Delta}{x[e_1] := e_2}{Write\ x\ \widehat{n}\  \widehat{m}}{skip}{H'}{A,x\mapsto\widehat{l}}{\Delta}
  }{w-e-set}
}{w-step}{Evaluation Relation of $\whileA$.}

Note that for $\evals{H_{0}}{A_{0}}{\Delta_{0}}{p_{0}}{Internal}{p_{1}}{H_{1}}{A_{1}}{\Delta_{1}}$ we write

$\evals{H_{0}}{A_{0}}{\Delta_{0}}{p_{0}}{}{p_{1}}{H_{1}}{A_{1}}{\Delta_{1}}$.

\myfig{
  $$
  \begin{array}{lllcl}
    grow & H & n & = & match\ n\ with \\
         &   &   & | & 0 \Rightarrow H \\
         &   &   & | & S m \Rightarrow 0 :: (grow\ H\ m) \\
  \end{array}
  $$
  \vspace{0.5cm}

  $$
  \begin{array}{lllcl}
    lookup & H & n & = & match\ n,H\ with \\
           &   &   & | & \_,[\ ] \Rightarrow None \\
           &   &   & | & 0,x :: \_ \Rightarrow Some\ x \\
           &   &   & | & S m,x :: xs \Rightarrow lookup\ xs \ m \\
  \end{array}
  $$
  \vspace{0.5cm}

  $$
  \begin{array}{lllcrl}
    replace & H & n & v = & match\ H\        & with  \\
           &   &   & | & [\ ] \Rightarrow    & [\ ] \\
           &   &   & | & x :: xs \Rightarrow & match\ n\ with \\
           &   &   &   &                   | & 0 \Rightarrow v :: xs \\
           &   &   &   &                   | & S m \Rightarrow x :: (replace\ xs\ m\ v) \\
  \end{array}
  $$
}{w-step-util}{Helper functions for heap manipulation.}

\clearpage

\begin{lemma}[$\whileA$ progress]
  Given $\typechecks{\Gamma}{p}{\Gamma'}$ there exist $\src{p'}, \src{b}, \src{H}, \src{H'}, \src{A}, \src{A'}, \src{\Delta}, \src{\Delta'}$ such that $\evals{H}{A}{\Delta}{p}{b}{p'}{H'}{A'}{\Delta'}$.
\end{lemma}
\begin{proof}
  Straightforward induction on $\typechecks{\Gamma}{p}{\Gamma'}$.
\end{proof}

\begin{lemma}[$\whileA$ preservation]
  Given $\typechecks{\Gamma}{p}{\Gamma'}$ and %
  $\evals{H}{A}{\Delta}{p}{b}{p'}{H'}{A'}{\Delta'}$ we have %
  $\exists \src{\Gamma''}, \typechecks{\Gamma'}{p'}{\Gamma''}$
\end{lemma}
\begin{proof}
  {\color{red} TODO}
\end{proof}

We define the following coinductive step relation to represent program executions that take an infinite number of steps.
\myfig{
  \typerule{$ce-more$}{
    \evals{H}{A}{\Delta}{p}{b}{p'}{H'}{A'}{\Delta'} &
    \Downarrow_\infty \src{p'}
	}{
    \Downarrow_\infty \src{p}
	}{w-infsteps-more}
}{while-arr-manysteps}{A \textit{coinductive} definition of $\whileA$ programs taking an infinite amount of steps.}

Using this, we can get a trace from an execution by defining $exec\ \src{p}$ as follows.
$$
\begin{array}{rll}
  mk\_trace\ \src{p}\ (H : \Downarrow_{\infty}\src{p}) &=& match\ H\ with\\
                                                       &|& (\evals{H}{A}{\Delta}{p}{b}{p'}{H'}{A'}{\Delta'},\  \Downarrow_{\infty}\src{p'}) \Rightarrow \seqcons{\src{b}}{(mk\_trace\ \src{p}\ (\Downarrow_{\infty}\src{p')})}\\
                                                      &end&
\end{array}
$$
\vspace{0.5cm}
$$
\begin{array}{rlcl}
  mk\_steps\ \src{p}\ \src{\Gamma}\ \src{\Gamma'}& (H:\typechecks{\Gamma}{p}{\Gamma'}) &=&\\
                                                 & let\ H' := progress\ H\ &in&match\ H'\ with\\
                                                 &                        &| &\exists \src{p'\ b\ H\ H\ A\ A'\ \Delta\ \Delta'}. H_{1} \Rightarrow\\
                                                 &                        &  & let\ H'' := preservation\ H_{1}\ H\ in\\
                                                 &                        &  & match\ H''\ with \\
                                                 &                        &  &|\ \exists \src{\Gamma_{0}}. H'''\Rightarrow more\ H_{1}\ (mk\_steps\ \src{p'}\ \src{\Gamma'}\ \src{\Gamma_{0}}\ H''') \\
                                                 &                        &  & end\\
                                                 &                        &end&

\end{array}
$$
\vspace{0.5cm}
$$
\begin{array}{rcl}
execute\ \src{p\ \Gamma\ \Gamma'} (H : \typechecks{\Gamma}{p}{\Gamma'}) := mk\_trace(mk\_steps\ H)
\end{array}
$$

We now define temporal memory safety in terms of traces on events $\src{e}$.

\begin{definition}[Unicity]
  Given an event $\src{e}$ and a trace $\trace$, the event $\src{e}$ occurs exactly once iff

  $\exists n, \trace[n]=\src{e} \wedge \not\exists m, n\not= m \wedge \trace[m] = \src{e}$
\end{definition}

\begin{definition}[Sequentiality]
  Given two events $\src{e_{0},e_{1}}$ and a trace $\trace$, event $\src{e_{0}}$ occurs before $\src{e_{1}}$ iff

  $\exists n, \trace[n] = \src{e_{0}}\implies \exists m, \trace[m] = \src{e_{1}} \wedge n<m$
\end{definition}

\begin{definition}[Temporal Memory Safety]
  Given any trace $\trace$, we say it is temporal memory safe iff

  $\forall v s, (\exists n, \trace[n] = \src{Alloc\ x\ \widehat{n}}) \implies one\_event\ (\src{Alloc\ v\ s})\ \trace\wedge one\_event\ (\src{Dealloc\ v})\ \trace\wedge after\_another\_event\ (\src{Alloc\ v\ s})\ (\src{Dealloc\ v})\ \trace$
\end{definition}

\begin{lemma}[$\whileA$ is temporal memory safe]
  $\rsat{\src{p}}{\src{tsafe}}$
\end{lemma}
\begin{proof}
  % TODO
\end{proof}

\clearpage

\bibliographystyle{plain}
\bibliography{library}

\end{document}
